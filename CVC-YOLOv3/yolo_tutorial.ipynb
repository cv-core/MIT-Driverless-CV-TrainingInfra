{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Train Your Own Cone Detection Networks\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22118253/70957091-fe06a480-2042-11ea-8c06-0fcc549fc19a.png)\n",
    "\n",
    "In this notebook, we will demonstrate \n",
    "- how to train your own YOLOv3-based traffic cone detection network and do inference on a video.\n",
    "\n",
    "**[Accurate Low Latency Visual Perception for Autonomous Racing: Challenges Mechanisms and Practical Solutions](https://github.com/mit-han-lab/once-for-all)** is an accurate low latency visual perception system introduced by Kieran Strobel, Sibo Zhu, Raphael Chang, and Skanda Koppula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation\n",
    "Let's first install all the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sudo apt install unzip\n",
    "print('Installing PyTorch...')\n",
    "! pip3 install torch \n",
    "print('Installing torchvision...')\n",
    "! pip3 install torchvision \n",
    "print('Installing numpy...')\n",
    "! pip3 install numpy \n",
    "# tqdm is a package for displaying a progress bar.\n",
    "print('Installing tqdm (progress bar) ...')\n",
    "! pip3 install tqdm \n",
    "print('Installing matplotlib...')\n",
    "! pip3 install matplotlib \n",
    "print('Installing all the other required packages once for all')\n",
    "! sudo python3 setup.py install\n",
    "print('Installing video editor')\n",
    "! sudo apt install ffmpeg -y "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training, let's download the Cone Detection dataset and the corresponding label and intial training weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading Training Dataset\")\n",
    "! wget https://storage.googleapis.com/mit-driverless-open-source/YOLO_Dataset.zip\n",
    "! unzip YOLO_Dataset.zip\n",
    "! mv YOLO_Dataset dataset/ && rm YOLO_Dataset.zip\n",
    "print(\"Downloading YOLOv3 Sample Weights\")\n",
    "! wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/sample-yolov3.weights \n",
    "print(\"Downloading Training and Validation Label\")\n",
    "! cd dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/all.csv && cd ..\n",
    "! cd dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/train.csv && cd ..\n",
    "! cd dataset/ && wget https://storage.googleapis.com/mit-driverless-open-source/yolov3-training/validate.csv && cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using Pretrained YOLOv3 Weights File to Start Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import all the packages used in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "import time\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import math\n",
    "import shutil\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from models import Darknet\n",
    "from utils.datasets import ImageLabelDataset\n",
    "from utils.utils import model_info, print_args, Logger, visualize_and_save_to_local,xywh2xyxy\n",
    "import validate\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "##### section for all random seeds #####\n",
    "torch.manual_seed(17)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "########################################\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "num_cpu = multiprocessing.cpu_count() if cuda else 0\n",
    "if cuda:\n",
    "    torch.cuda.synchronize()\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successfully imported all packages and configured random seed to 17!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(label_prefix, data_loader, num_steps, optimizer, model, epoch, num_epochs, step):\n",
    "    print(f\"Model in {label_prefix} mode\")\n",
    "    epoch_losses = [0.0] * 7\n",
    "    epoch_time_total = 0.0\n",
    "    epoch_num_targets = 1e-12\n",
    "    t1 = time.time()\n",
    "    loss_labels = [\"Total\", \"L-x\", \"L-y\", \"L-w\", \"L-h\", \"L-noobj\", \"L-obj\"]\n",
    "    for i, (img_uri, imgs, targets) in enumerate(data_loader):\n",
    "        if step[0] >= num_steps:\n",
    "            break\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        targets.requires_grad_(False)\n",
    "        step_num_targets = ((targets[:, :, 1:5] > 0).sum(dim=2) > 1).sum().item() + 1e-12\n",
    "        epoch_num_targets += step_num_targets\n",
    "        # Compute loss, compute gradient, update parameters\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "        losses = model(imgs, targets)\n",
    "        if label_prefix == \"train\":\n",
    "            losses[0].sum().backward()\n",
    "        if optimizer is not None:\n",
    "            optimizer.step()\n",
    "\n",
    "        for j, (label, loss) in enumerate(zip(loss_labels, losses)):\n",
    "            batch_loss = loss.sum().to('cpu').item()\n",
    "            epoch_losses[j] += batch_loss\n",
    "        finished_time = time.time()\n",
    "        step_time_total = finished_time - t1\n",
    "        epoch_time_total += step_time_total\n",
    "        \n",
    "        statement = label_prefix + ' Epoch: ' + str(epoch) + ', Batch: ' + str(i + 1) + '/' + str(len(data_loader))\n",
    "        count = 0\n",
    "        for (loss_label, loss) in zip(loss_labels, losses):\n",
    "            if count == 0:\n",
    "                statement += ', Total: ' + '{0:10.6f}'.format(loss.item() / step_num_targets)\n",
    "                tot_loss = loss.item()\n",
    "                count += 1\n",
    "            else:\n",
    "                statement += ',   ' + loss_label + ': {0:5.2f}'.format(loss.item() / tot_loss * 100) + '%'\n",
    "        print(statement)\n",
    "        if label_prefix == \"train\":\n",
    "            step[0] += 1\n",
    "    return epoch_losses, epoch_time_total, epoch_num_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = False\n",
    "batch_size = int(5)\n",
    "optimizer_pick = \"Adam\"\n",
    "model_cfg = \"model_cfg/yolo_baseline.cfg\"\n",
    "weights_path = \"sample-yolov3.weights\"\n",
    "output_path = \"automatic\"\n",
    "dataset_path = \"dataset/YOLO_Dataset/\"\n",
    "num_epochs = int(2048)\n",
    "num_steps = 8388608\n",
    "checkpoint_interval = int(1)\n",
    "augment_affine = False\n",
    "augment_hsv = False\n",
    "lr_flip = False\n",
    "ud_flip = False\n",
    "momentum = float(0.9)\n",
    "gamma = float(0.95)\n",
    "lr = float(0.001)\n",
    "weight_decay = float(0.0)\n",
    "vis_batch = int(0)\n",
    "data_aug = False\n",
    "blur = False\n",
    "salt = False\n",
    "noise = False\n",
    "contrast = False\n",
    "sharpen = False\n",
    "ts = True\n",
    "debug_mode = False\n",
    "upload_dataset = False\n",
    "xy_loss = float(2)\n",
    "wh_loss= float(1.6)\n",
    "no_object_loss = float(25)\n",
    "object_loss = float(0.1)\n",
    "vanilla_anchor = False\n",
    "val_tolerance = int(3)\n",
    "min_epochs = int(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model\n",
      "Initializing data loaders\n",
      "Num train images:  15132\n",
      "Num validate images:  3077\n",
      "Training batch size: 5\n",
      "Checkpoint interval: 1\n",
      "Loss constants: [2.0, 1.6, 25.0, 0.1]\n",
      "Anchor boxes: [[13.477251565102941, 11.575637337941961], [22.26137229153354, 17.66822633636613], [33.064472956296804, 25.977976230935123], [46.576946122512396, 36.33784567190777], [62.933468143405676, 48.888459798286966], [81.89252731448791, 65.28682918216337], [108.42925619967495, 83.93800920523023], [151.85350492775095, 108.38056296607171], [224.56576162251665, 148.38432899717495]]\n",
      "Training image width: 800\n",
      "Training image height: 800\n",
      "Confidence Threshold: 0.8\n",
      "Number of training classes: 80\n",
      "Conv activation type: leaky\n",
      "Starting learning rate: 0.001\n",
      "Tile and scale mode [on]\n",
      "Data augmentation mode [off]\n",
      "Using Adam Optimizer\n",
      "Loading weights\n",
      "Model in train mode\n",
      "train Epoch: 1, Batch: 1/3027, Total:   0.140322,   L-x:  1.75%,   L-y:  1.65%,   L-w: 39.55%,   L-h: 16.81%,   L-noobj:  5.19%,   L-obj: 35.06%\n",
      "train Epoch: 1, Batch: 2/3027, Total:   0.197732,   L-x:  2.41%,   L-y:  4.75%,   L-w: 13.70%,   L-h: 16.99%,   L-noobj:  1.90%,   L-obj: 60.24%\n",
      "train Epoch: 1, Batch: 3/3027, Total:   0.122544,   L-x:  4.03%,   L-y:  3.28%,   L-w: 19.73%,   L-h: 13.95%,   L-noobj:  3.58%,   L-obj: 55.44%\n",
      "train Epoch: 1, Batch: 4/3027, Total:   0.092719,   L-x:  3.03%,   L-y:  4.31%,   L-w: 19.23%,   L-h: 16.80%,   L-noobj:  1.83%,   L-obj: 54.79%\n",
      "train Epoch: 1, Batch: 5/3027, Total:   0.147386,   L-x:  5.98%,   L-y:  4.04%,   L-w: 12.73%,   L-h: 12.84%,   L-noobj: 17.37%,   L-obj: 47.04%\n",
      "train Epoch: 1, Batch: 6/3027, Total:  11.874244,   L-x:  0.07%,   L-y:  0.06%,   L-w: 49.52%,   L-h: 50.00%,   L-noobj:  0.12%,   L-obj:  0.22%\n",
      "train Epoch: 1, Batch: 7/3027, Total:  14.129425,   L-x:  0.04%,   L-y:  0.04%,   L-w: 49.97%,   L-h: 49.72%,   L-noobj:  0.11%,   L-obj:  0.11%\n",
      "train Epoch: 1, Batch: 8/3027, Total:   0.077301,   L-x:  4.51%,   L-y:  6.87%,   L-w: 18.91%,   L-h: 17.90%,   L-noobj: 29.12%,   L-obj: 22.68%\n",
      "train Epoch: 1, Batch: 9/3027, Total:   0.083902,   L-x:  8.28%,   L-y:  9.67%,   L-w: 27.35%,   L-h: 13.60%,   L-noobj: 19.72%,   L-obj: 21.38%\n",
      "train Epoch: 1, Batch: 10/3027, Total:   0.060627,   L-x:  5.47%,   L-y:  7.84%,   L-w: 21.32%,   L-h: 14.94%,   L-noobj: 26.86%,   L-obj: 23.57%\n",
      "train Epoch: 1, Batch: 11/3027, Total:   0.117278,   L-x:  4.15%,   L-y:  5.60%,   L-w: 31.76%,   L-h: 22.73%,   L-noobj: 29.39%,   L-obj:  6.36%\n",
      "train Epoch: 1, Batch: 12/3027, Total:   0.066020,   L-x:  9.27%,   L-y:  9.01%,   L-w: 25.94%,   L-h: 18.79%,   L-noobj: 23.37%,   L-obj: 13.63%\n",
      "train Epoch: 1, Batch: 13/3027, Total:   0.043569,   L-x:  7.71%,   L-y:  7.46%,   L-w: 22.42%,   L-h: 20.71%,   L-noobj: 20.82%,   L-obj: 20.88%\n",
      "train Epoch: 1, Batch: 14/3027, Total:   0.047889,   L-x:  8.03%,   L-y:  9.73%,   L-w: 16.59%,   L-h: 22.16%,   L-noobj: 31.84%,   L-obj: 11.65%\n",
      "train Epoch: 1, Batch: 15/3027, Total:   8.922197,   L-x:  0.04%,   L-y:  0.05%,   L-w: 51.64%,   L-h: 47.84%,   L-noobj:  0.34%,   L-obj:  0.10%\n",
      "train Epoch: 1, Batch: 16/3027, Total:   0.067990,   L-x:  5.84%,   L-y:  7.42%,   L-w: 17.62%,   L-h: 21.10%,   L-noobj: 30.57%,   L-obj: 17.45%\n",
      "train Epoch: 1, Batch: 17/3027, Total:  13.978512,   L-x:  0.04%,   L-y:  0.05%,   L-w: 50.27%,   L-h: 49.44%,   L-noobj:  0.15%,   L-obj:  0.06%\n",
      "train Epoch: 1, Batch: 18/3027, Total:   0.038887,   L-x:  6.38%,   L-y:  6.70%,   L-w: 23.59%,   L-h: 16.33%,   L-noobj:  5.94%,   L-obj: 41.06%\n",
      "train Epoch: 1, Batch: 19/3027, Total:   0.057099,   L-x:  5.53%,   L-y:  8.40%,   L-w: 29.93%,   L-h: 26.27%,   L-noobj: 12.94%,   L-obj: 16.92%\n",
      "train Epoch: 1, Batch: 20/3027, Total:   0.127662,   L-x:  5.56%,   L-y:  5.50%,   L-w: 16.01%,   L-h: 22.61%,   L-noobj: 37.79%,   L-obj: 12.53%\n",
      "train Epoch: 1, Batch: 21/3027, Total:   0.117530,   L-x:  4.65%,   L-y:  6.74%,   L-w: 23.54%,   L-h: 30.43%,   L-noobj: 26.72%,   L-obj:  7.93%\n",
      "train Epoch: 1, Batch: 22/3027, Total:   0.045409,   L-x:  7.25%,   L-y:  5.73%,   L-w: 32.33%,   L-h: 29.07%,   L-noobj: 16.89%,   L-obj:  8.73%\n",
      "train Epoch: 1, Batch: 23/3027, Total:   0.026904,   L-x:  5.53%,   L-y:  9.26%,   L-w: 24.33%,   L-h: 15.48%,   L-noobj: 10.60%,   L-obj: 34.80%\n",
      "train Epoch: 1, Batch: 24/3027, Total:   0.250740,   L-x:  3.38%,   L-y:  3.83%,   L-w: 20.42%,   L-h: 41.49%,   L-noobj: 26.30%,   L-obj:  4.57%\n",
      "train Epoch: 1, Batch: 25/3027, Total:   0.166085,   L-x:  6.38%,   L-y:  6.41%,   L-w: 25.84%,   L-h: 26.56%,   L-noobj: 23.08%,   L-obj: 11.74%\n",
      "train Epoch: 1, Batch: 26/3027, Total:   0.047907,   L-x:  7.32%,   L-y:  6.87%,   L-w: 25.02%,   L-h: 25.00%,   L-noobj: 27.07%,   L-obj:  8.73%\n",
      "train Epoch: 1, Batch: 27/3027, Total:   0.050366,   L-x:  6.89%,   L-y:  9.09%,   L-w: 20.26%,   L-h: 27.26%,   L-noobj: 18.59%,   L-obj: 17.91%\n",
      "train Epoch: 1, Batch: 28/3027, Total:   0.043680,   L-x:  8.63%,   L-y:  9.87%,   L-w: 18.37%,   L-h: 19.18%,   L-noobj: 28.56%,   L-obj: 15.39%\n",
      "train Epoch: 1, Batch: 29/3027, Total:   0.064322,   L-x:  8.15%,   L-y:  5.97%,   L-w: 23.44%,   L-h: 24.98%,   L-noobj: 30.05%,   L-obj:  7.41%\n",
      "train Epoch: 1, Batch: 30/3027, Total:   0.075268,   L-x:  6.27%,   L-y:  6.06%,   L-w: 20.04%,   L-h: 34.44%,   L-noobj: 23.29%,   L-obj:  9.90%\n",
      "train Epoch: 1, Batch: 31/3027, Total:   0.051777,   L-x:  5.86%,   L-y:  8.51%,   L-w: 34.95%,   L-h: 24.19%,   L-noobj: 18.38%,   L-obj:  8.11%\n",
      "train Epoch: 1, Batch: 32/3027, Total:   0.038630,   L-x:  8.11%,   L-y:  6.79%,   L-w: 24.22%,   L-h: 29.95%,   L-noobj: 24.10%,   L-obj:  6.83%\n",
      "train Epoch: 1, Batch: 33/3027, Total:   0.100095,   L-x:  3.23%,   L-y:  3.70%,   L-w: 34.42%,   L-h: 22.43%,   L-noobj: 32.10%,   L-obj:  4.11%\n",
      "train Epoch: 1, Batch: 34/3027, Total:   4.844865,   L-x:  0.05%,   L-y:  0.06%,   L-w: 49.60%,   L-h: 50.08%,   L-noobj:  0.09%,   L-obj:  0.11%\n",
      "train Epoch: 1, Batch: 35/3027, Total:   0.048448,   L-x:  7.12%,   L-y:  6.26%,   L-w: 27.69%,   L-h: 24.26%,   L-noobj: 26.93%,   L-obj:  7.74%\n",
      "train Epoch: 1, Batch: 36/3027, Total:   0.063217,   L-x:  8.02%,   L-y:  9.77%,   L-w: 25.37%,   L-h: 16.49%,   L-noobj: 31.58%,   L-obj:  8.77%\n",
      "train Epoch: 1, Batch: 37/3027, Total:   0.094134,   L-x:  8.01%,   L-y:  6.38%,   L-w: 28.00%,   L-h: 19.12%,   L-noobj: 32.76%,   L-obj:  5.73%\n",
      "train Epoch: 1, Batch: 38/3027, Total:   0.103811,   L-x:  8.05%,   L-y:  9.56%,   L-w: 19.79%,   L-h: 21.60%,   L-noobj: 35.91%,   L-obj:  5.08%\n",
      "train Epoch: 1, Batch: 39/3027, Total:   0.070570,   L-x:  7.59%,   L-y:  8.28%,   L-w: 24.52%,   L-h: 21.75%,   L-noobj: 17.66%,   L-obj: 20.20%\n",
      "train Epoch: 1, Batch: 40/3027, Total:   0.084355,   L-x:  4.96%,   L-y:  6.63%,   L-w: 27.12%,   L-h: 27.73%,   L-noobj: 20.88%,   L-obj: 12.68%\n",
      "train Epoch: 1, Batch: 41/3027, Total:   0.040535,   L-x:  8.17%,   L-y: 10.97%,   L-w: 17.69%,   L-h: 15.27%,   L-noobj: 35.83%,   L-obj: 12.07%\n",
      "train Epoch: 1, Batch: 42/3027, Total:   0.058722,   L-x:  9.36%,   L-y:  7.69%,   L-w: 19.40%,   L-h: 19.42%,   L-noobj: 32.42%,   L-obj: 11.71%\n",
      "train Epoch: 1, Batch: 43/3027, Total:   5.933285,   L-x:  0.06%,   L-y:  0.06%,   L-w: 50.41%,   L-h: 49.16%,   L-noobj:  0.18%,   L-obj:  0.14%\n",
      "train Epoch: 1, Batch: 44/3027, Total:   5.218372,   L-x:  0.07%,   L-y:  0.09%,   L-w: 50.48%,   L-h: 49.07%,   L-noobj:  0.19%,   L-obj:  0.10%\n",
      "train Epoch: 1, Batch: 45/3027, Total:  42.096261,   L-x:  0.03%,   L-y:  0.02%,   L-w: 50.88%,   L-h: 48.93%,   L-noobj:  0.11%,   L-obj:  0.04%\n",
      "train Epoch: 1, Batch: 46/3027, Total:   0.024601,   L-x:  6.64%,   L-y:  5.89%,   L-w: 23.00%,   L-h: 24.33%,   L-noobj: 21.89%,   L-obj: 18.25%\n",
      "train Epoch: 1, Batch: 47/3027, Total:   0.048112,   L-x:  9.61%,   L-y: 10.02%,   L-w: 22.06%,   L-h: 19.23%,   L-noobj: 28.85%,   L-obj: 10.22%\n",
      "train Epoch: 1, Batch: 48/3027, Total:   6.349128,   L-x:  0.07%,   L-y:  0.06%,   L-w: 50.71%,   L-h: 48.90%,   L-noobj:  0.15%,   L-obj:  0.12%\n",
      "train Epoch: 1, Batch: 49/3027, Total:   0.046972,   L-x:  3.83%,   L-y:  6.45%,   L-w: 35.93%,   L-h: 25.94%,   L-noobj: 11.59%,   L-obj: 16.27%\n",
      "train Epoch: 1, Batch: 50/3027, Total:   7.894845,   L-x:  0.07%,   L-y:  0.06%,   L-w: 52.15%,   L-h: 47.42%,   L-noobj:  0.22%,   L-obj:  0.07%\n",
      "train Epoch: 1, Batch: 51/3027, Total:   0.172285,   L-x:  4.90%,   L-y:  4.58%,   L-w: 21.40%,   L-h: 39.52%,   L-noobj: 22.88%,   L-obj:  6.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 52/3027, Total:   0.054506,   L-x: 10.77%,   L-y:  7.58%,   L-w: 28.01%,   L-h: 23.82%,   L-noobj: 17.99%,   L-obj: 11.82%\n",
      "train Epoch: 1, Batch: 53/3027, Total:   0.070273,   L-x: 10.07%,   L-y:  7.80%,   L-w: 30.77%,   L-h: 17.91%,   L-noobj: 16.89%,   L-obj: 16.56%\n",
      "train Epoch: 1, Batch: 54/3027, Total:   0.048401,   L-x:  6.80%,   L-y:  4.91%,   L-w: 29.45%,   L-h: 29.46%,   L-noobj: 15.74%,   L-obj: 13.64%\n",
      "train Epoch: 1, Batch: 55/3027, Total:   0.100840,   L-x:  3.98%,   L-y:  5.65%,   L-w: 23.96%,   L-h: 48.14%,   L-noobj: 10.84%,   L-obj:  7.43%\n",
      "train Epoch: 1, Batch: 56/3027, Total:   0.036935,   L-x: 10.56%,   L-y:  7.83%,   L-w: 24.39%,   L-h: 15.10%,   L-noobj: 28.65%,   L-obj: 13.46%\n",
      "train Epoch: 1, Batch: 57/3027, Total:   9.066699,   L-x:  0.03%,   L-y:  0.04%,   L-w: 54.93%,   L-h: 44.39%,   L-noobj:  0.49%,   L-obj:  0.11%\n",
      "train Epoch: 1, Batch: 58/3027, Total:   0.074776,   L-x:  3.12%,   L-y:  3.62%,   L-w: 36.13%,   L-h: 25.39%,   L-noobj: 23.37%,   L-obj:  8.37%\n",
      "train Epoch: 1, Batch: 59/3027, Total:   4.156656,   L-x:  0.13%,   L-y:  0.10%,   L-w: 53.85%,   L-h: 44.87%,   L-noobj:  0.91%,   L-obj:  0.14%\n",
      "train Epoch: 1, Batch: 60/3027, Total:  19.433117,   L-x:  0.05%,   L-y:  0.02%,   L-w: 53.16%,   L-h: 46.13%,   L-noobj:  0.57%,   L-obj:  0.07%\n",
      "train Epoch: 1, Batch: 61/3027, Total:   0.081691,   L-x:  7.00%,   L-y:  5.21%,   L-w: 29.36%,   L-h: 25.85%,   L-noobj: 22.48%,   L-obj: 10.11%\n",
      "train Epoch: 1, Batch: 62/3027, Total:   0.110935,   L-x:  4.92%,   L-y:  4.38%,   L-w: 32.54%,   L-h: 31.57%,   L-noobj: 19.04%,   L-obj:  7.55%\n",
      "train Epoch: 1, Batch: 63/3027, Total:   0.053362,   L-x:  5.31%,   L-y:  7.69%,   L-w: 22.72%,   L-h: 19.03%,   L-noobj: 31.68%,   L-obj: 13.56%\n",
      "train Epoch: 1, Batch: 64/3027, Total:   0.174760,   L-x:  4.14%,   L-y:  4.83%,   L-w: 22.24%,   L-h: 26.37%,   L-noobj: 30.82%,   L-obj: 11.60%\n",
      "train Epoch: 1, Batch: 65/3027, Total:   0.110365,   L-x:  2.76%,   L-y:  3.60%,   L-w: 27.84%,   L-h: 35.88%,   L-noobj: 19.47%,   L-obj: 10.45%\n",
      "train Epoch: 1, Batch: 66/3027, Total:  57.137325,   L-x:  0.02%,   L-y:  0.03%,   L-w: 44.26%,   L-h: 55.30%,   L-noobj:  0.31%,   L-obj:  0.07%\n",
      "train Epoch: 1, Batch: 67/3027, Total:   0.049367,   L-x:  6.11%,   L-y:  8.68%,   L-w: 22.55%,   L-h: 16.75%,   L-noobj: 18.90%,   L-obj: 27.01%\n",
      "train Epoch: 1, Batch: 68/3027, Total:   0.140019,   L-x:  3.51%,   L-y:  4.94%,   L-w: 31.59%,   L-h: 24.89%,   L-noobj: 29.88%,   L-obj:  5.20%\n",
      "train Epoch: 1, Batch: 69/3027, Total:   2.662061,   L-x:  0.20%,   L-y:  0.20%,   L-w: 46.71%,   L-h: 51.16%,   L-noobj:  1.55%,   L-obj:  0.18%\n",
      "train Epoch: 1, Batch: 70/3027, Total:   0.085053,   L-x:  5.63%,   L-y:  6.23%,   L-w: 29.88%,   L-h: 14.03%,   L-noobj: 34.84%,   L-obj:  9.40%\n",
      "train Epoch: 1, Batch: 71/3027, Total:   0.086050,   L-x:  3.37%,   L-y:  4.29%,   L-w: 35.60%,   L-h: 22.18%,   L-noobj: 29.29%,   L-obj:  5.28%\n",
      "train Epoch: 1, Batch: 72/3027, Total:   0.064851,   L-x:  4.57%,   L-y:  4.15%,   L-w: 32.13%,   L-h: 25.33%,   L-noobj: 28.36%,   L-obj:  5.46%\n",
      "train Epoch: 1, Batch: 73/3027, Total:   0.075658,   L-x:  5.05%,   L-y:  5.11%,   L-w: 28.74%,   L-h: 32.21%,   L-noobj: 25.74%,   L-obj:  3.16%\n",
      "train Epoch: 1, Batch: 74/3027, Total:   5.665127,   L-x:  0.16%,   L-y:  0.15%,   L-w: 51.13%,   L-h: 47.42%,   L-noobj:  1.02%,   L-obj:  0.11%\n",
      "train Epoch: 1, Batch: 75/3027, Total:   0.255786,   L-x:  3.21%,   L-y:  6.62%,   L-w: 34.97%,   L-h: 26.88%,   L-noobj: 26.08%,   L-obj:  2.24%\n",
      "train Epoch: 1, Batch: 76/3027, Total:   0.091954,   L-x:  3.61%,   L-y:  3.72%,   L-w: 40.33%,   L-h: 31.28%,   L-noobj: 17.27%,   L-obj:  3.79%\n",
      "train Epoch: 1, Batch: 77/3027, Total:   0.368274,   L-x:  1.20%,   L-y:  1.46%,   L-w: 42.72%,   L-h: 47.52%,   L-noobj:  5.88%,   L-obj:  1.21%\n",
      "train Epoch: 1, Batch: 78/3027, Total:   0.077173,   L-x:  3.00%,   L-y:  6.35%,   L-w: 31.03%,   L-h: 31.14%,   L-noobj: 23.28%,   L-obj:  5.20%\n",
      "train Epoch: 1, Batch: 79/3027, Total:   0.068155,   L-x:  5.66%,   L-y:  9.50%,   L-w: 23.72%,   L-h: 24.46%,   L-noobj: 32.42%,   L-obj:  4.24%\n",
      "train Epoch: 1, Batch: 80/3027, Total:   0.066611,   L-x:  4.90%,   L-y:  5.47%,   L-w: 34.64%,   L-h: 31.35%,   L-noobj: 19.10%,   L-obj:  4.54%\n",
      "train Epoch: 1, Batch: 81/3027, Total:   0.050566,   L-x:  3.80%,   L-y:  4.72%,   L-w: 31.28%,   L-h: 32.43%,   L-noobj: 21.41%,   L-obj:  6.36%\n",
      "train Epoch: 1, Batch: 82/3027, Total:   0.074561,   L-x:  7.09%,   L-y:  4.94%,   L-w: 25.76%,   L-h: 26.89%,   L-noobj: 28.81%,   L-obj:  6.51%\n",
      "train Epoch: 1, Batch: 83/3027, Total:   3.925192,   L-x:  0.07%,   L-y:  0.07%,   L-w: 49.24%,   L-h: 49.46%,   L-noobj:  1.00%,   L-obj:  0.16%\n",
      "train Epoch: 1, Batch: 84/3027, Total:   0.037539,   L-x:  7.32%,   L-y:  4.20%,   L-w: 28.48%,   L-h: 26.33%,   L-noobj: 26.33%,   L-obj:  7.34%\n",
      "train Epoch: 1, Batch: 85/3027, Total:   0.070609,   L-x:  3.68%,   L-y:  5.22%,   L-w: 30.57%,   L-h: 25.79%,   L-noobj: 30.33%,   L-obj:  4.41%\n",
      "train Epoch: 1, Batch: 86/3027, Total:   0.078170,   L-x:  6.04%,   L-y:  3.39%,   L-w: 31.88%,   L-h: 28.66%,   L-noobj: 19.14%,   L-obj: 10.88%\n",
      "train Epoch: 1, Batch: 87/3027, Total:   0.038284,   L-x:  6.52%,   L-y:  3.89%,   L-w: 31.54%,   L-h: 28.78%,   L-noobj: 13.96%,   L-obj: 15.31%\n",
      "train Epoch: 1, Batch: 88/3027, Total:   0.066507,   L-x:  3.10%,   L-y:  4.96%,   L-w: 33.93%,   L-h: 30.62%,   L-noobj: 22.23%,   L-obj:  5.17%\n",
      "train Epoch: 1, Batch: 89/3027, Total:   0.078565,   L-x:  6.52%,   L-y:  6.52%,   L-w: 32.52%,   L-h: 23.60%,   L-noobj: 24.47%,   L-obj:  6.38%\n",
      "train Epoch: 1, Batch: 90/3027, Total:   3.835395,   L-x:  0.14%,   L-y:  0.12%,   L-w: 50.71%,   L-h: 47.44%,   L-noobj:  1.37%,   L-obj:  0.22%\n",
      "train Epoch: 1, Batch: 91/3027, Total:   0.109925,   L-x:  6.06%,   L-y:  5.88%,   L-w: 32.02%,   L-h: 25.54%,   L-noobj: 24.59%,   L-obj:  5.91%\n",
      "train Epoch: 1, Batch: 92/3027, Total:   0.081159,   L-x:  3.81%,   L-y:  4.86%,   L-w: 35.96%,   L-h: 31.24%,   L-noobj: 18.42%,   L-obj:  5.72%\n",
      "train Epoch: 1, Batch: 93/3027, Total:   0.050469,   L-x:  3.81%,   L-y:  3.08%,   L-w: 37.52%,   L-h: 34.86%,   L-noobj: 14.34%,   L-obj:  6.39%\n",
      "train Epoch: 1, Batch: 94/3027, Total:   1.211001,   L-x:  0.28%,   L-y:  0.28%,   L-w: 49.57%,   L-h: 47.77%,   L-noobj:  1.63%,   L-obj:  0.47%\n",
      "train Epoch: 1, Batch: 95/3027, Total:   0.070530,   L-x:  6.09%,   L-y:  5.66%,   L-w: 35.72%,   L-h: 24.67%,   L-noobj: 16.59%,   L-obj: 11.28%\n",
      "train Epoch: 1, Batch: 96/3027, Total:   0.048136,   L-x:  8.27%,   L-y: 12.47%,   L-w: 30.23%,   L-h: 24.83%,   L-noobj: 14.69%,   L-obj:  9.50%\n",
      "train Epoch: 1, Batch: 97/3027, Total:   0.129334,   L-x:  4.11%,   L-y:  6.89%,   L-w: 31.02%,   L-h: 31.56%,   L-noobj: 20.75%,   L-obj:  5.67%\n",
      "train Epoch: 1, Batch: 98/3027, Total:   2.229757,   L-x:  0.19%,   L-y:  0.44%,   L-w: 48.50%,   L-h: 48.37%,   L-noobj:  2.07%,   L-obj:  0.44%\n",
      "train Epoch: 1, Batch: 99/3027, Total:   0.864482,   L-x:  0.31%,   L-y:  0.28%,   L-w: 48.57%,   L-h: 47.83%,   L-noobj:  2.39%,   L-obj:  0.64%\n",
      "train Epoch: 1, Batch: 100/3027, Total:   0.045370,   L-x:  8.14%,   L-y:  6.81%,   L-w: 23.54%,   L-h: 30.96%,   L-noobj: 13.11%,   L-obj: 17.44%\n",
      "train Epoch: 1, Batch: 101/3027, Total:   0.232220,   L-x:  1.47%,   L-y:  1.85%,   L-w: 41.53%,   L-h: 45.55%,   L-noobj:  4.83%,   L-obj:  4.78%\n",
      "train Epoch: 1, Batch: 102/3027, Total:   0.064521,   L-x:  8.38%,   L-y:  7.89%,   L-w: 28.41%,   L-h: 18.96%,   L-noobj: 24.47%,   L-obj: 11.89%\n",
      "train Epoch: 1, Batch: 103/3027, Total:   0.078805,   L-x:  6.75%,   L-y:  7.91%,   L-w: 30.76%,   L-h: 20.30%,   L-noobj: 26.89%,   L-obj:  7.39%\n",
      "train Epoch: 1, Batch: 104/3027, Total:   0.190270,   L-x:  4.07%,   L-y:  2.84%,   L-w: 31.93%,   L-h: 40.47%,   L-noobj: 14.58%,   L-obj:  6.12%\n",
      "train Epoch: 1, Batch: 105/3027, Total:   0.102354,   L-x:  3.76%,   L-y:  2.79%,   L-w: 43.20%,   L-h: 35.95%,   L-noobj:  9.95%,   L-obj:  4.34%\n",
      "train Epoch: 1, Batch: 106/3027, Total:   0.143666,   L-x:  2.24%,   L-y:  8.94%,   L-w: 36.25%,   L-h: 31.37%,   L-noobj: 15.30%,   L-obj:  5.91%\n",
      "train Epoch: 1, Batch: 107/3027, Total:   0.076274,   L-x:  3.34%,   L-y:  3.55%,   L-w: 34.36%,   L-h: 41.12%,   L-noobj: 13.60%,   L-obj:  4.03%\n",
      "train Epoch: 1, Batch: 108/3027, Total:   0.068268,   L-x:  5.84%,   L-y:  6.57%,   L-w: 29.80%,   L-h: 22.10%,   L-noobj: 26.21%,   L-obj:  9.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 109/3027, Total:   0.082496,   L-x:  4.76%,   L-y:  5.46%,   L-w: 39.27%,   L-h: 26.11%,   L-noobj: 16.71%,   L-obj:  7.68%\n",
      "train Epoch: 1, Batch: 110/3027, Total:   0.552456,   L-x:  0.72%,   L-y:  0.40%,   L-w: 44.09%,   L-h: 48.60%,   L-noobj:  5.31%,   L-obj:  0.89%\n",
      "train Epoch: 1, Batch: 111/3027, Total:   0.044107,   L-x:  4.38%,   L-y:  5.63%,   L-w: 33.30%,   L-h: 26.69%,   L-noobj:  9.20%,   L-obj: 20.80%\n",
      "train Epoch: 1, Batch: 112/3027, Total:   0.093454,   L-x:  8.43%,   L-y:  9.25%,   L-w: 30.52%,   L-h: 24.27%,   L-noobj: 16.99%,   L-obj: 10.55%\n",
      "train Epoch: 1, Batch: 113/3027, Total:   1.241210,   L-x:  0.45%,   L-y:  0.36%,   L-w: 42.23%,   L-h: 46.20%,   L-noobj: 10.04%,   L-obj:  0.73%\n",
      "train Epoch: 1, Batch: 114/3027, Total:   0.131975,   L-x:  3.08%,   L-y:  4.01%,   L-w: 30.57%,   L-h: 33.98%,   L-noobj: 24.34%,   L-obj:  4.02%\n",
      "train Epoch: 1, Batch: 115/3027, Total:   0.091512,   L-x:  8.45%,   L-y:  3.93%,   L-w: 34.04%,   L-h: 32.21%,   L-noobj: 13.50%,   L-obj:  7.87%\n",
      "train Epoch: 1, Batch: 116/3027, Total:   0.094743,   L-x:  7.36%,   L-y:  6.42%,   L-w: 28.09%,   L-h: 28.12%,   L-noobj: 22.00%,   L-obj:  8.01%\n",
      "train Epoch: 1, Batch: 117/3027, Total:   0.047599,   L-x:  7.79%,   L-y:  4.33%,   L-w: 30.81%,   L-h: 24.48%,   L-noobj: 20.85%,   L-obj: 11.74%\n",
      "train Epoch: 1, Batch: 118/3027, Total:   0.069594,   L-x:  7.31%,   L-y:  8.72%,   L-w: 22.56%,   L-h: 23.67%,   L-noobj: 27.02%,   L-obj: 10.72%\n",
      "train Epoch: 1, Batch: 119/3027, Total:   0.216364,   L-x:  3.43%,   L-y:  3.89%,   L-w: 36.20%,   L-h: 37.15%,   L-noobj: 16.87%,   L-obj:  2.46%\n",
      "train Epoch: 1, Batch: 120/3027, Total:   0.119041,   L-x:  5.79%,   L-y:  5.17%,   L-w: 26.65%,   L-h: 32.15%,   L-noobj: 22.08%,   L-obj:  8.15%\n",
      "train Epoch: 1, Batch: 121/3027, Total:   0.232182,   L-x:  0.98%,   L-y:  1.59%,   L-w: 41.53%,   L-h: 42.97%,   L-noobj: 11.20%,   L-obj:  1.73%\n",
      "train Epoch: 1, Batch: 122/3027, Total:   0.128834,   L-x:  4.38%,   L-y:  5.34%,   L-w: 27.29%,   L-h: 30.44%,   L-noobj: 19.41%,   L-obj: 13.15%\n",
      "train Epoch: 1, Batch: 123/3027, Total:   0.117018,   L-x:  3.92%,   L-y:  4.46%,   L-w: 41.61%,   L-h: 31.14%,   L-noobj: 14.97%,   L-obj:  3.90%\n",
      "train Epoch: 1, Batch: 124/3027, Total:   0.250033,   L-x:  2.12%,   L-y:  3.33%,   L-w: 38.46%,   L-h: 38.26%,   L-noobj: 14.83%,   L-obj:  3.00%\n",
      "train Epoch: 1, Batch: 125/3027, Total:   0.052265,   L-x:  6.86%,   L-y:  7.45%,   L-w: 29.07%,   L-h: 36.18%,   L-noobj: 12.14%,   L-obj:  8.30%\n",
      "train Epoch: 1, Batch: 126/3027, Total:   0.049707,   L-x:  5.69%,   L-y:  7.14%,   L-w: 32.58%,   L-h: 32.53%,   L-noobj: 16.00%,   L-obj:  6.07%\n",
      "train Epoch: 1, Batch: 127/3027, Total:   0.053135,   L-x:  7.28%,   L-y:  9.47%,   L-w: 23.64%,   L-h: 30.84%,   L-noobj: 21.93%,   L-obj:  6.84%\n",
      "train Epoch: 1, Batch: 128/3027, Total:   0.209642,   L-x:  4.66%,   L-y:  9.72%,   L-w: 27.96%,   L-h: 26.71%,   L-noobj: 26.63%,   L-obj:  4.32%\n",
      "train Epoch: 1, Batch: 129/3027, Total:   0.046663,   L-x:  7.92%,   L-y:  8.40%,   L-w: 25.60%,   L-h: 18.52%,   L-noobj: 35.44%,   L-obj:  4.12%\n",
      "train Epoch: 1, Batch: 130/3027, Total:   0.041693,   L-x:  7.21%,   L-y:  6.32%,   L-w: 29.90%,   L-h: 24.48%,   L-noobj: 21.69%,   L-obj: 10.41%\n",
      "train Epoch: 1, Batch: 131/3027, Total:   0.329913,   L-x:  1.91%,   L-y:  1.67%,   L-w: 41.44%,   L-h: 36.69%,   L-noobj: 14.58%,   L-obj:  3.71%\n",
      "train Epoch: 1, Batch: 132/3027, Total:   0.080104,   L-x: 10.94%,   L-y:  5.41%,   L-w: 28.01%,   L-h: 27.02%,   L-noobj: 13.76%,   L-obj: 14.86%\n",
      "train Epoch: 1, Batch: 133/3027, Total:   0.051574,   L-x:  3.93%,   L-y:  6.59%,   L-w: 26.02%,   L-h: 26.87%,   L-noobj: 18.16%,   L-obj: 18.43%\n",
      "train Epoch: 1, Batch: 134/3027, Total:   0.061830,   L-x:  8.50%,   L-y:  9.37%,   L-w: 26.43%,   L-h: 23.92%,   L-noobj: 25.56%,   L-obj:  6.21%\n",
      "train Epoch: 1, Batch: 135/3027, Total:   0.022988,   L-x: 12.33%,   L-y:  9.04%,   L-w: 20.82%,   L-h: 31.21%,   L-noobj:  8.74%,   L-obj: 17.86%\n",
      "train Epoch: 1, Batch: 136/3027, Total:   0.052324,   L-x: 12.77%,   L-y:  8.26%,   L-w: 28.22%,   L-h: 22.29%,   L-noobj: 13.17%,   L-obj: 15.29%\n",
      "train Epoch: 1, Batch: 137/3027, Total:   0.055385,   L-x:  7.13%,   L-y:  7.10%,   L-w: 32.04%,   L-h: 25.28%,   L-noobj: 18.35%,   L-obj: 10.11%\n",
      "train Epoch: 1, Batch: 138/3027, Total:   0.057070,   L-x:  9.04%,   L-y:  6.07%,   L-w: 30.62%,   L-h: 31.69%,   L-noobj: 16.60%,   L-obj:  5.99%\n",
      "train Epoch: 1, Batch: 139/3027, Total:   0.054589,   L-x:  8.70%,   L-y:  6.62%,   L-w: 22.19%,   L-h: 24.59%,   L-noobj: 16.33%,   L-obj: 21.56%\n",
      "train Epoch: 1, Batch: 140/3027, Total:   0.040923,   L-x:  8.88%,   L-y: 11.36%,   L-w: 29.07%,   L-h: 18.68%,   L-noobj: 21.71%,   L-obj: 10.30%\n",
      "train Epoch: 1, Batch: 141/3027, Total:   0.028606,   L-x:  7.06%,   L-y:  7.17%,   L-w: 27.58%,   L-h: 21.53%,   L-noobj: 25.29%,   L-obj: 11.37%\n",
      "train Epoch: 1, Batch: 142/3027, Total:   0.057533,   L-x:  6.55%,   L-y:  7.28%,   L-w: 37.71%,   L-h: 28.27%,   L-noobj:  9.99%,   L-obj: 10.19%\n",
      "train Epoch: 1, Batch: 143/3027, Total:   0.041987,   L-x:  6.86%,   L-y:  6.58%,   L-w: 35.92%,   L-h: 22.86%,   L-noobj: 14.56%,   L-obj: 13.22%\n",
      "train Epoch: 1, Batch: 144/3027, Total:   0.810544,   L-x:  0.75%,   L-y:  1.26%,   L-w: 43.69%,   L-h: 44.47%,   L-noobj:  8.65%,   L-obj:  1.20%\n",
      "train Epoch: 1, Batch: 145/3027, Total:   0.023832,   L-x:  7.53%,   L-y:  8.13%,   L-w: 36.89%,   L-h: 21.42%,   L-noobj: 14.18%,   L-obj: 11.86%\n",
      "train Epoch: 1, Batch: 146/3027, Total:   0.033775,   L-x:  8.31%,   L-y:  7.90%,   L-w: 28.52%,   L-h: 29.29%,   L-noobj: 13.89%,   L-obj: 12.08%\n",
      "train Epoch: 1, Batch: 147/3027, Total:   0.051798,   L-x:  8.41%,   L-y:  9.22%,   L-w: 26.62%,   L-h: 29.49%,   L-noobj: 11.92%,   L-obj: 14.34%\n",
      "train Epoch: 1, Batch: 148/3027, Total:   0.060189,   L-x:  4.73%,   L-y:  6.72%,   L-w: 27.56%,   L-h: 36.73%,   L-noobj: 16.84%,   L-obj:  7.44%\n",
      "train Epoch: 1, Batch: 149/3027, Total:   0.072371,   L-x:  8.15%,   L-y:  9.94%,   L-w: 29.92%,   L-h: 28.00%,   L-noobj: 16.33%,   L-obj:  7.66%\n",
      "train Epoch: 1, Batch: 150/3027, Total:   0.130430,   L-x:  6.79%,   L-y:  5.48%,   L-w: 28.44%,   L-h: 38.52%,   L-noobj: 13.72%,   L-obj:  7.05%\n",
      "train Epoch: 1, Batch: 151/3027, Total:   0.086387,   L-x:  8.14%,   L-y:  6.76%,   L-w: 26.87%,   L-h: 22.33%,   L-noobj: 25.06%,   L-obj: 10.85%\n",
      "train Epoch: 1, Batch: 152/3027, Total:   0.327047,   L-x:  0.76%,   L-y:  0.65%,   L-w: 62.72%,   L-h: 32.35%,   L-noobj:  2.80%,   L-obj:  0.71%\n",
      "train Epoch: 1, Batch: 153/3027, Total:   0.046651,   L-x:  6.66%,   L-y:  6.68%,   L-w: 34.15%,   L-h: 19.06%,   L-noobj: 24.99%,   L-obj:  8.46%\n",
      "train Epoch: 1, Batch: 154/3027, Total:   0.117624,   L-x:  4.40%,   L-y:  4.91%,   L-w: 32.10%,   L-h: 30.48%,   L-noobj: 23.88%,   L-obj:  4.23%\n",
      "train Epoch: 1, Batch: 155/3027, Total:   0.040128,   L-x: 11.67%,   L-y:  9.75%,   L-w: 27.93%,   L-h: 21.77%,   L-noobj: 17.39%,   L-obj: 11.50%\n",
      "train Epoch: 1, Batch: 156/3027, Total:   0.028522,   L-x:  8.94%,   L-y:  7.86%,   L-w: 25.58%,   L-h: 25.62%,   L-noobj: 18.81%,   L-obj: 13.18%\n",
      "train Epoch: 1, Batch: 157/3027, Total:   0.042849,   L-x: 10.94%,   L-y:  9.39%,   L-w: 25.55%,   L-h: 22.08%,   L-noobj: 16.56%,   L-obj: 15.48%\n",
      "train Epoch: 1, Batch: 158/3027, Total:   0.024171,   L-x:  8.01%,   L-y: 10.40%,   L-w: 25.91%,   L-h: 32.49%,   L-noobj: 10.77%,   L-obj: 12.42%\n",
      "train Epoch: 1, Batch: 159/3027, Total:   0.070578,   L-x:  7.28%,   L-y:  9.87%,   L-w: 31.65%,   L-h: 20.40%,   L-noobj: 26.70%,   L-obj:  4.10%\n",
      "train Epoch: 1, Batch: 160/3027, Total:   0.078369,   L-x:  6.61%,   L-y:  8.09%,   L-w: 33.66%,   L-h: 25.98%,   L-noobj: 20.01%,   L-obj:  5.64%\n",
      "train Epoch: 1, Batch: 161/3027, Total:   0.064728,   L-x:  8.77%,   L-y: 10.02%,   L-w: 25.53%,   L-h: 27.62%,   L-noobj: 16.05%,   L-obj: 12.01%\n",
      "train Epoch: 1, Batch: 162/3027, Total:   0.058216,   L-x:  8.54%,   L-y: 10.16%,   L-w: 32.14%,   L-h: 23.89%,   L-noobj: 12.02%,   L-obj: 13.25%\n",
      "train Epoch: 1, Batch: 163/3027, Total:   0.035720,   L-x:  8.36%,   L-y:  7.67%,   L-w: 28.76%,   L-h: 19.24%,   L-noobj: 19.84%,   L-obj: 16.13%\n",
      "train Epoch: 1, Batch: 164/3027, Total:   0.029840,   L-x:  5.91%,   L-y:  6.90%,   L-w: 28.74%,   L-h: 31.53%,   L-noobj: 16.39%,   L-obj: 10.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 165/3027, Total:   0.374381,   L-x:  1.41%,   L-y:  1.37%,   L-w: 37.31%,   L-h: 41.14%,   L-noobj: 16.33%,   L-obj:  2.44%\n",
      "train Epoch: 1, Batch: 166/3027, Total:   0.073205,   L-x: 12.83%,   L-y:  8.98%,   L-w: 28.66%,   L-h: 29.58%,   L-noobj: 12.20%,   L-obj:  7.74%\n",
      "train Epoch: 1, Batch: 167/3027, Total:   0.140436,   L-x:  2.20%,   L-y:  2.82%,   L-w: 32.66%,   L-h: 43.86%,   L-noobj: 15.56%,   L-obj:  2.90%\n",
      "train Epoch: 1, Batch: 168/3027, Total:   0.047532,   L-x: 10.34%,   L-y:  9.84%,   L-w: 27.53%,   L-h: 15.76%,   L-noobj: 25.22%,   L-obj: 11.29%\n",
      "train Epoch: 1, Batch: 169/3027, Total:   0.060610,   L-x:  8.81%,   L-y:  9.53%,   L-w: 20.47%,   L-h: 20.42%,   L-noobj: 33.83%,   L-obj:  6.94%\n",
      "train Epoch: 1, Batch: 170/3027, Total:   0.069860,   L-x:  5.45%,   L-y:  7.46%,   L-w: 30.62%,   L-h: 26.78%,   L-noobj: 20.78%,   L-obj:  8.91%\n",
      "train Epoch: 1, Batch: 171/3027, Total:   0.067053,   L-x:  4.12%,   L-y:  3.22%,   L-w: 28.12%,   L-h: 29.08%,   L-noobj: 31.10%,   L-obj:  4.36%\n",
      "train Epoch: 1, Batch: 172/3027, Total:   0.084334,   L-x:  4.64%,   L-y:  4.63%,   L-w: 28.36%,   L-h: 18.93%,   L-noobj: 36.40%,   L-obj:  7.04%\n",
      "train Epoch: 1, Batch: 173/3027, Total:   0.116223,   L-x:  3.25%,   L-y:  3.47%,   L-w: 26.78%,   L-h: 25.54%,   L-noobj: 36.35%,   L-obj:  4.62%\n",
      "train Epoch: 1, Batch: 174/3027, Total:   0.048703,   L-x:  8.31%,   L-y:  9.38%,   L-w: 24.84%,   L-h: 24.23%,   L-noobj: 22.58%,   L-obj: 10.67%\n",
      "train Epoch: 1, Batch: 175/3027, Total:   0.037374,   L-x: 12.67%,   L-y: 11.02%,   L-w: 26.30%,   L-h: 18.93%,   L-noobj: 18.17%,   L-obj: 12.90%\n",
      "train Epoch: 1, Batch: 176/3027, Total:   0.026517,   L-x:  8.91%,   L-y:  4.82%,   L-w: 32.09%,   L-h: 27.00%,   L-noobj:  9.94%,   L-obj: 17.24%\n",
      "train Epoch: 1, Batch: 177/3027, Total:   0.402707,   L-x:  2.06%,   L-y:  3.20%,   L-w: 32.24%,   L-h: 29.76%,   L-noobj: 30.31%,   L-obj:  2.43%\n",
      "train Epoch: 1, Batch: 178/3027, Total:   0.076831,   L-x:  5.21%,   L-y:  5.17%,   L-w: 32.08%,   L-h: 24.97%,   L-noobj: 28.39%,   L-obj:  4.18%\n",
      "train Epoch: 1, Batch: 179/3027, Total:   0.059519,   L-x:  7.67%,   L-y:  6.73%,   L-w: 29.67%,   L-h: 30.47%,   L-noobj: 12.45%,   L-obj: 13.01%\n",
      "train Epoch: 1, Batch: 180/3027, Total:   0.018379,   L-x:  5.78%,   L-y:  5.88%,   L-w: 31.66%,   L-h: 25.33%,   L-noobj: 15.37%,   L-obj: 15.98%\n",
      "train Epoch: 1, Batch: 181/3027, Total:   0.074856,   L-x:  4.44%,   L-y:  2.73%,   L-w: 35.23%,   L-h: 33.04%,   L-noobj: 20.67%,   L-obj:  3.90%\n",
      "train Epoch: 1, Batch: 182/3027, Total:   0.075316,   L-x:  4.23%,   L-y:  4.04%,   L-w: 41.16%,   L-h: 33.48%,   L-noobj:  9.96%,   L-obj:  7.13%\n",
      "train Epoch: 1, Batch: 183/3027, Total:   0.052929,   L-x:  9.45%,   L-y:  8.81%,   L-w: 30.74%,   L-h: 25.11%,   L-noobj: 12.86%,   L-obj: 13.04%\n",
      "train Epoch: 1, Batch: 184/3027, Total:   0.020896,   L-x: 11.13%,   L-y:  8.62%,   L-w: 25.41%,   L-h: 24.06%,   L-noobj: 17.91%,   L-obj: 12.87%\n",
      "train Epoch: 1, Batch: 185/3027, Total:   0.026765,   L-x: 10.88%,   L-y:  9.70%,   L-w: 20.72%,   L-h: 15.31%,   L-noobj: 24.73%,   L-obj: 18.65%\n",
      "train Epoch: 1, Batch: 186/3027, Total:   0.056341,   L-x:  7.62%,   L-y:  6.80%,   L-w: 32.81%,   L-h: 32.81%,   L-noobj: 13.73%,   L-obj:  6.22%\n",
      "train Epoch: 1, Batch: 187/3027, Total:   0.963059,   L-x:  0.97%,   L-y:  0.89%,   L-w: 41.56%,   L-h: 42.24%,   L-noobj: 13.88%,   L-obj:  0.47%\n",
      "train Epoch: 1, Batch: 188/3027, Total:   0.049404,   L-x:  6.87%,   L-y:  9.08%,   L-w: 22.96%,   L-h: 23.57%,   L-noobj: 27.21%,   L-obj: 10.32%\n",
      "train Epoch: 1, Batch: 189/3027, Total:   0.068675,   L-x:  3.40%,   L-y:  4.58%,   L-w: 21.11%,   L-h: 18.25%,   L-noobj: 46.62%,   L-obj:  6.04%\n",
      "train Epoch: 1, Batch: 190/3027, Total:   0.128264,   L-x:  4.95%,   L-y:  8.37%,   L-w: 16.69%,   L-h: 30.93%,   L-noobj: 34.45%,   L-obj:  4.62%\n",
      "train Epoch: 1, Batch: 191/3027, Total:   0.044023,   L-x:  7.49%,   L-y: 12.15%,   L-w: 23.05%,   L-h: 25.32%,   L-noobj: 23.51%,   L-obj:  8.49%\n",
      "train Epoch: 1, Batch: 192/3027, Total:   0.418349,   L-x:  1.01%,   L-y:  1.57%,   L-w: 40.64%,   L-h: 50.91%,   L-noobj:  5.05%,   L-obj:  0.81%\n",
      "train Epoch: 1, Batch: 193/3027, Total:   0.051004,   L-x:  6.79%,   L-y:  8.99%,   L-w: 31.51%,   L-h: 26.87%,   L-noobj: 14.75%,   L-obj: 11.09%\n",
      "train Epoch: 1, Batch: 194/3027, Total:   0.019489,   L-x:  9.98%,   L-y: 12.52%,   L-w: 27.84%,   L-h: 25.21%,   L-noobj: 12.17%,   L-obj: 12.28%\n",
      "train Epoch: 1, Batch: 195/3027, Total:   0.056096,   L-x:  9.70%,   L-y:  9.53%,   L-w: 24.48%,   L-h: 23.71%,   L-noobj: 18.29%,   L-obj: 14.30%\n",
      "train Epoch: 1, Batch: 196/3027, Total:   0.419272,   L-x:  0.62%,   L-y:  1.22%,   L-w: 42.13%,   L-h: 46.86%,   L-noobj:  8.07%,   L-obj:  1.11%\n",
      "train Epoch: 1, Batch: 197/3027, Total:   0.056103,   L-x:  7.23%,   L-y:  9.07%,   L-w: 18.86%,   L-h: 31.46%,   L-noobj: 27.74%,   L-obj:  5.64%\n",
      "train Epoch: 1, Batch: 198/3027, Total:   0.683956,   L-x:  1.11%,   L-y:  0.50%,   L-w: 43.35%,   L-h: 45.65%,   L-noobj:  8.40%,   L-obj:  0.99%\n",
      "train Epoch: 1, Batch: 199/3027, Total:   0.051889,   L-x: 10.22%,   L-y:  5.86%,   L-w: 38.28%,   L-h: 18.56%,   L-noobj: 14.48%,   L-obj: 12.59%\n",
      "train Epoch: 1, Batch: 200/3027, Total:   0.043882,   L-x: 11.77%,   L-y: 11.31%,   L-w: 23.86%,   L-h: 24.11%,   L-noobj: 16.90%,   L-obj: 12.04%\n",
      "train Epoch: 1, Batch: 201/3027, Total:   0.026415,   L-x:  7.37%,   L-y:  8.02%,   L-w: 20.13%,   L-h: 20.94%,   L-noobj: 19.60%,   L-obj: 23.95%\n",
      "train Epoch: 1, Batch: 202/3027, Total:   0.096606,   L-x:  5.22%,   L-y:  6.93%,   L-w: 28.16%,   L-h: 26.61%,   L-noobj: 28.71%,   L-obj:  4.37%\n",
      "train Epoch: 1, Batch: 203/3027, Total:   0.035159,   L-x:  9.72%,   L-y:  8.31%,   L-w: 21.05%,   L-h: 17.04%,   L-noobj: 34.39%,   L-obj:  9.49%\n",
      "train Epoch: 1, Batch: 204/3027, Total:   0.032719,   L-x:  5.77%,   L-y:  7.43%,   L-w: 33.53%,   L-h: 27.60%,   L-noobj: 17.17%,   L-obj:  8.49%\n",
      "train Epoch: 1, Batch: 205/3027, Total:   0.024710,   L-x:  9.95%,   L-y: 11.29%,   L-w: 29.66%,   L-h: 21.79%,   L-noobj: 12.68%,   L-obj: 14.62%\n",
      "train Epoch: 1, Batch: 206/3027, Total:   0.059145,   L-x:  5.42%,   L-y:  7.77%,   L-w: 33.76%,   L-h: 28.03%,   L-noobj: 15.75%,   L-obj:  9.27%\n",
      "train Epoch: 1, Batch: 207/3027, Total:   0.022009,   L-x: 10.59%,   L-y: 10.94%,   L-w: 27.20%,   L-h: 17.80%,   L-noobj: 22.11%,   L-obj: 11.35%\n",
      "train Epoch: 1, Batch: 208/3027, Total:   0.025552,   L-x:  9.55%,   L-y:  9.09%,   L-w: 24.07%,   L-h: 24.72%,   L-noobj: 18.16%,   L-obj: 14.43%\n",
      "train Epoch: 1, Batch: 209/3027, Total:   0.036612,   L-x:  9.26%,   L-y:  9.39%,   L-w: 29.30%,   L-h: 21.98%,   L-noobj: 17.27%,   L-obj: 12.79%\n",
      "train Epoch: 1, Batch: 210/3027, Total:   0.053803,   L-x:  8.27%,   L-y:  8.87%,   L-w: 23.01%,   L-h: 22.05%,   L-noobj: 32.55%,   L-obj:  5.24%\n",
      "train Epoch: 1, Batch: 211/3027, Total:   0.020290,   L-x:  8.76%,   L-y: 13.77%,   L-w: 26.66%,   L-h: 18.02%,   L-noobj: 16.90%,   L-obj: 15.90%\n",
      "train Epoch: 1, Batch: 212/3027, Total:   0.317006,   L-x:  1.75%,   L-y:  1.72%,   L-w: 41.36%,   L-h: 45.02%,   L-noobj:  9.15%,   L-obj:  1.00%\n",
      "train Epoch: 1, Batch: 213/3027, Total:   0.715471,   L-x:  0.73%,   L-y:  0.87%,   L-w: 39.26%,   L-h: 41.75%,   L-noobj: 16.38%,   L-obj:  1.02%\n",
      "train Epoch: 1, Batch: 214/3027, Total:   0.062345,   L-x: 10.24%,   L-y: 10.77%,   L-w: 25.02%,   L-h: 20.73%,   L-noobj: 28.52%,   L-obj:  4.72%\n",
      "train Epoch: 1, Batch: 215/3027, Total:   0.044267,   L-x:  4.54%,   L-y:  6.37%,   L-w: 36.29%,   L-h: 24.79%,   L-noobj: 20.67%,   L-obj:  7.34%\n",
      "train Epoch: 1, Batch: 216/3027, Total:   0.192714,   L-x:  4.59%,   L-y:  5.26%,   L-w: 28.94%,   L-h: 24.30%,   L-noobj: 33.69%,   L-obj:  3.22%\n",
      "train Epoch: 1, Batch: 217/3027, Total:   0.040561,   L-x:  7.54%,   L-y:  9.56%,   L-w: 32.14%,   L-h: 24.28%,   L-noobj: 16.67%,   L-obj:  9.81%\n",
      "train Epoch: 1, Batch: 218/3027, Total:   0.026561,   L-x:  9.35%,   L-y:  9.55%,   L-w: 22.26%,   L-h: 18.65%,   L-noobj: 28.57%,   L-obj: 11.61%\n",
      "train Epoch: 1, Batch: 219/3027, Total:   0.106740,   L-x:  6.57%,   L-y:  8.18%,   L-w: 32.50%,   L-h: 21.22%,   L-noobj: 22.67%,   L-obj:  8.87%\n",
      "train Epoch: 1, Batch: 220/3027, Total:   0.094212,   L-x:  6.23%,   L-y: 10.76%,   L-w: 30.38%,   L-h: 23.64%,   L-noobj: 21.15%,   L-obj:  7.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 221/3027, Total:   0.050320,   L-x: 10.05%,   L-y: 11.43%,   L-w: 26.46%,   L-h: 19.44%,   L-noobj: 21.22%,   L-obj: 11.40%\n",
      "train Epoch: 1, Batch: 222/3027, Total:   0.062805,   L-x: 11.81%,   L-y: 11.20%,   L-w: 23.86%,   L-h: 21.54%,   L-noobj: 22.86%,   L-obj:  8.74%\n",
      "train Epoch: 1, Batch: 223/3027, Total:   0.029124,   L-x: 10.71%,   L-y: 11.22%,   L-w: 36.68%,   L-h: 16.40%,   L-noobj:  8.19%,   L-obj: 16.80%\n",
      "train Epoch: 1, Batch: 224/3027, Total:   0.075955,   L-x:  7.28%,   L-y:  8.37%,   L-w: 34.97%,   L-h: 24.86%,   L-noobj: 17.52%,   L-obj:  6.99%\n",
      "train Epoch: 1, Batch: 225/3027, Total:   0.043580,   L-x:  8.11%,   L-y: 11.80%,   L-w: 23.24%,   L-h: 23.97%,   L-noobj: 20.59%,   L-obj: 12.30%\n",
      "train Epoch: 1, Batch: 226/3027, Total:   0.029883,   L-x:  8.10%,   L-y:  7.34%,   L-w: 27.09%,   L-h: 29.16%,   L-noobj: 13.96%,   L-obj: 14.35%\n",
      "train Epoch: 1, Batch: 227/3027, Total:   0.277330,   L-x:  2.70%,   L-y:  2.11%,   L-w: 30.81%,   L-h: 35.86%,   L-noobj: 25.23%,   L-obj:  3.29%\n",
      "train Epoch: 1, Batch: 228/3027, Total:   0.187083,   L-x:  3.08%,   L-y:  4.06%,   L-w: 28.75%,   L-h: 28.77%,   L-noobj: 32.27%,   L-obj:  3.07%\n",
      "train Epoch: 1, Batch: 229/3027, Total:   0.053543,   L-x:  6.35%,   L-y: 10.87%,   L-w: 26.76%,   L-h: 20.83%,   L-noobj: 22.80%,   L-obj: 12.39%\n",
      "train Epoch: 1, Batch: 230/3027, Total:   0.049809,   L-x: 11.14%,   L-y:  8.15%,   L-w: 29.37%,   L-h: 24.34%,   L-noobj: 15.73%,   L-obj: 11.27%\n",
      "train Epoch: 1, Batch: 231/3027, Total:   0.032678,   L-x:  5.91%,   L-y: 13.59%,   L-w: 26.04%,   L-h: 16.40%,   L-noobj: 15.49%,   L-obj: 22.57%\n",
      "train Epoch: 1, Batch: 232/3027, Total:   0.057784,   L-x: 10.76%,   L-y: 10.40%,   L-w: 26.08%,   L-h: 23.08%,   L-noobj: 20.10%,   L-obj:  9.58%\n",
      "train Epoch: 1, Batch: 233/3027, Total:   0.026134,   L-x:  6.26%,   L-y:  7.51%,   L-w: 27.36%,   L-h: 24.37%,   L-noobj: 21.09%,   L-obj: 13.41%\n",
      "train Epoch: 1, Batch: 234/3027, Total:   0.051403,   L-x:  6.34%,   L-y: 10.78%,   L-w: 26.64%,   L-h: 25.19%,   L-noobj: 20.80%,   L-obj: 10.24%\n",
      "train Epoch: 1, Batch: 235/3027, Total:   0.039066,   L-x:  8.19%,   L-y:  7.48%,   L-w: 23.68%,   L-h: 19.97%,   L-noobj: 31.60%,   L-obj:  9.08%\n",
      "train Epoch: 1, Batch: 236/3027, Total:   2.246473,   L-x:  0.15%,   L-y:  0.21%,   L-w: 43.58%,   L-h: 43.03%,   L-noobj: 12.58%,   L-obj:  0.45%\n",
      "train Epoch: 1, Batch: 237/3027, Total:   0.044708,   L-x:  9.64%,   L-y:  9.31%,   L-w: 21.55%,   L-h: 24.90%,   L-noobj: 19.76%,   L-obj: 14.84%\n",
      "train Epoch: 1, Batch: 238/3027, Total:   0.069713,   L-x:  5.49%,   L-y:  6.08%,   L-w: 17.71%,   L-h: 17.02%,   L-noobj: 48.19%,   L-obj:  5.50%\n",
      "train Epoch: 1, Batch: 239/3027, Total:   0.043583,   L-x: 10.42%,   L-y: 12.91%,   L-w: 18.86%,   L-h: 22.13%,   L-noobj: 23.45%,   L-obj: 12.24%\n",
      "train Epoch: 1, Batch: 240/3027, Total:   0.032732,   L-x:  5.50%,   L-y:  6.15%,   L-w: 31.01%,   L-h: 28.39%,   L-noobj: 18.62%,   L-obj: 10.33%\n",
      "train Epoch: 1, Batch: 241/3027, Total:   0.045848,   L-x: 11.06%,   L-y: 12.02%,   L-w: 17.17%,   L-h: 12.72%,   L-noobj: 31.55%,   L-obj: 15.48%\n",
      "train Epoch: 1, Batch: 242/3027, Total:   0.181409,   L-x:  1.79%,   L-y:  1.14%,   L-w: 42.19%,   L-h: 39.17%,   L-noobj: 13.69%,   L-obj:  2.01%\n",
      "train Epoch: 1, Batch: 243/3027, Total:   2.402142,   L-x:  0.59%,   L-y:  0.43%,   L-w: 45.76%,   L-h: 45.49%,   L-noobj:  7.39%,   L-obj:  0.35%\n",
      "train Epoch: 1, Batch: 244/3027, Total:   0.041631,   L-x:  9.29%,   L-y: 10.26%,   L-w: 24.29%,   L-h: 17.90%,   L-noobj: 21.05%,   L-obj: 17.20%\n",
      "train Epoch: 1, Batch: 245/3027, Total:   0.019520,   L-x: 11.28%,   L-y: 13.16%,   L-w: 25.05%,   L-h: 17.44%,   L-noobj: 17.85%,   L-obj: 15.22%\n",
      "train Epoch: 1, Batch: 246/3027, Total:   0.041106,   L-x:  8.74%,   L-y:  9.99%,   L-w: 24.98%,   L-h: 24.05%,   L-noobj: 23.18%,   L-obj:  9.06%\n",
      "train Epoch: 1, Batch: 247/3027, Total:   0.047245,   L-x:  8.90%,   L-y: 14.18%,   L-w: 21.18%,   L-h: 15.50%,   L-noobj: 26.43%,   L-obj: 13.81%\n",
      "train Epoch: 1, Batch: 248/3027, Total:   0.029331,   L-x: 10.02%,   L-y:  9.97%,   L-w: 26.93%,   L-h: 22.26%,   L-noobj: 22.78%,   L-obj:  8.03%\n",
      "train Epoch: 1, Batch: 249/3027, Total:   0.101708,   L-x:  2.27%,   L-y:  2.52%,   L-w: 39.03%,   L-h: 37.96%,   L-noobj: 16.25%,   L-obj:  1.98%\n",
      "train Epoch: 1, Batch: 250/3027, Total:   0.075461,   L-x:  6.36%,   L-y:  6.59%,   L-w: 24.15%,   L-h: 19.40%,   L-noobj: 37.86%,   L-obj:  5.64%\n",
      "train Epoch: 1, Batch: 251/3027, Total:   0.029400,   L-x:  8.84%,   L-y: 13.46%,   L-w: 20.66%,   L-h: 18.89%,   L-noobj: 16.85%,   L-obj: 21.30%\n",
      "train Epoch: 1, Batch: 252/3027, Total:   0.015644,   L-x: 11.62%,   L-y:  9.84%,   L-w: 20.92%,   L-h: 20.63%,   L-noobj: 28.65%,   L-obj:  8.34%\n",
      "train Epoch: 1, Batch: 253/3027, Total:   0.063327,   L-x:  6.12%,   L-y:  8.66%,   L-w: 30.47%,   L-h: 28.32%,   L-noobj: 20.70%,   L-obj:  5.73%\n",
      "train Epoch: 1, Batch: 254/3027, Total:   0.040868,   L-x: 10.08%,   L-y: 10.58%,   L-w: 27.63%,   L-h: 19.77%,   L-noobj: 22.13%,   L-obj:  9.81%\n",
      "train Epoch: 1, Batch: 255/3027, Total:   0.051061,   L-x:  8.86%,   L-y: 11.47%,   L-w: 29.83%,   L-h: 25.71%,   L-noobj: 16.00%,   L-obj:  8.13%\n",
      "train Epoch: 1, Batch: 256/3027, Total:   0.170151,   L-x:  2.54%,   L-y:  2.10%,   L-w: 36.60%,   L-h: 38.74%,   L-noobj: 18.35%,   L-obj:  1.68%\n",
      "train Epoch: 1, Batch: 257/3027, Total:   0.037619,   L-x:  8.92%,   L-y:  6.39%,   L-w: 27.88%,   L-h: 21.57%,   L-noobj: 25.02%,   L-obj: 10.22%\n",
      "train Epoch: 1, Batch: 258/3027, Total:   0.035496,   L-x:  8.90%,   L-y:  9.42%,   L-w: 29.20%,   L-h: 22.75%,   L-noobj: 17.84%,   L-obj: 11.88%\n",
      "train Epoch: 1, Batch: 259/3027, Total:   0.072500,   L-x:  9.86%,   L-y:  9.94%,   L-w: 25.39%,   L-h: 21.04%,   L-noobj: 23.03%,   L-obj: 10.74%\n",
      "train Epoch: 1, Batch: 260/3027, Total:   0.058908,   L-x:  5.92%,   L-y:  6.80%,   L-w: 34.55%,   L-h: 29.92%,   L-noobj: 15.78%,   L-obj:  7.04%\n",
      "train Epoch: 1, Batch: 261/3027, Total:   0.074002,   L-x: 10.34%,   L-y: 13.88%,   L-w: 24.70%,   L-h: 19.15%,   L-noobj: 26.10%,   L-obj:  5.83%\n",
      "train Epoch: 1, Batch: 262/3027, Total:   0.030542,   L-x: 11.30%,   L-y:  9.34%,   L-w: 25.91%,   L-h: 15.84%,   L-noobj: 28.53%,   L-obj:  9.08%\n",
      "train Epoch: 1, Batch: 263/3027, Total:   0.284530,   L-x:  1.55%,   L-y:  2.52%,   L-w: 38.93%,   L-h: 37.81%,   L-noobj: 17.61%,   L-obj:  1.58%\n",
      "train Epoch: 1, Batch: 264/3027, Total:   0.171841,   L-x:  5.90%,   L-y:  3.25%,   L-w: 27.60%,   L-h: 25.96%,   L-noobj: 34.11%,   L-obj:  3.18%\n",
      "train Epoch: 1, Batch: 265/3027, Total:   0.028858,   L-x:  8.95%,   L-y: 13.72%,   L-w: 24.05%,   L-h: 23.65%,   L-noobj: 17.80%,   L-obj: 11.84%\n",
      "train Epoch: 1, Batch: 266/3027, Total:   0.049673,   L-x: 14.46%,   L-y:  7.60%,   L-w: 20.14%,   L-h: 19.96%,   L-noobj: 29.60%,   L-obj:  8.23%\n",
      "train Epoch: 1, Batch: 267/3027, Total:   0.048461,   L-x:  5.38%,   L-y:  5.96%,   L-w: 33.19%,   L-h: 27.47%,   L-noobj: 21.33%,   L-obj:  6.67%\n",
      "train Epoch: 1, Batch: 268/3027, Total:   0.056274,   L-x:  4.54%,   L-y:  4.52%,   L-w: 28.78%,   L-h: 27.93%,   L-noobj: 29.85%,   L-obj:  4.38%\n",
      "train Epoch: 1, Batch: 269/3027, Total:   0.045033,   L-x:  6.42%,   L-y:  7.22%,   L-w: 39.73%,   L-h: 19.85%,   L-noobj: 15.56%,   L-obj: 11.21%\n",
      "train Epoch: 1, Batch: 270/3027, Total:   0.047209,   L-x:  6.56%,   L-y:  7.87%,   L-w: 28.72%,   L-h: 23.90%,   L-noobj: 26.48%,   L-obj:  6.49%\n",
      "train Epoch: 1, Batch: 271/3027, Total:   0.035991,   L-x:  8.03%,   L-y: 13.34%,   L-w: 30.09%,   L-h: 19.79%,   L-noobj: 15.71%,   L-obj: 13.04%\n",
      "train Epoch: 1, Batch: 272/3027, Total:   0.061565,   L-x: 10.37%,   L-y: 11.60%,   L-w: 19.37%,   L-h: 12.77%,   L-noobj: 38.55%,   L-obj:  7.36%\n",
      "train Epoch: 1, Batch: 273/3027, Total:   0.034851,   L-x:  7.53%,   L-y: 11.17%,   L-w: 25.08%,   L-h: 22.41%,   L-noobj: 17.93%,   L-obj: 15.88%\n",
      "train Epoch: 1, Batch: 274/3027, Total:   0.068436,   L-x:  8.90%,   L-y:  9.94%,   L-w: 28.53%,   L-h: 24.32%,   L-noobj: 20.41%,   L-obj:  7.90%\n",
      "train Epoch: 1, Batch: 275/3027, Total:   0.052076,   L-x:  5.09%,   L-y:  5.86%,   L-w: 31.00%,   L-h: 28.39%,   L-noobj: 22.11%,   L-obj:  7.55%\n",
      "train Epoch: 1, Batch: 276/3027, Total:   0.676316,   L-x:  0.26%,   L-y:  0.55%,   L-w: 41.34%,   L-h: 42.92%,   L-noobj: 13.50%,   L-obj:  1.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 277/3027, Total:   0.030217,   L-x:  9.94%,   L-y: 10.15%,   L-w: 22.73%,   L-h: 12.82%,   L-noobj: 28.03%,   L-obj: 16.33%\n",
      "train Epoch: 1, Batch: 278/3027, Total:   0.034928,   L-x: 12.72%,   L-y:  7.68%,   L-w: 22.94%,   L-h: 29.39%,   L-noobj: 16.72%,   L-obj: 10.56%\n",
      "train Epoch: 1, Batch: 279/3027, Total:   0.041309,   L-x:  5.62%,   L-y: 11.11%,   L-w: 26.90%,   L-h: 27.61%,   L-noobj: 14.11%,   L-obj: 14.64%\n",
      "train Epoch: 1, Batch: 280/3027, Total:   0.042718,   L-x:  9.29%,   L-y:  9.32%,   L-w: 25.54%,   L-h: 18.44%,   L-noobj: 19.28%,   L-obj: 18.11%\n",
      "train Epoch: 1, Batch: 281/3027, Total:   0.031070,   L-x: 10.30%,   L-y:  6.69%,   L-w: 31.14%,   L-h: 20.21%,   L-noobj: 15.01%,   L-obj: 16.66%\n",
      "train Epoch: 1, Batch: 282/3027, Total:   0.179202,   L-x:  3.63%,   L-y:  3.50%,   L-w: 32.42%,   L-h: 33.55%,   L-noobj: 23.56%,   L-obj:  3.34%\n",
      "train Epoch: 1, Batch: 283/3027, Total:   0.148569,   L-x:  4.25%,   L-y:  4.18%,   L-w: 17.44%,   L-h: 33.17%,   L-noobj: 38.91%,   L-obj:  2.05%\n",
      "train Epoch: 1, Batch: 284/3027, Total:   0.052884,   L-x:  4.13%,   L-y:  6.51%,   L-w: 23.76%,   L-h: 15.17%,   L-noobj: 41.44%,   L-obj:  9.00%\n",
      "train Epoch: 1, Batch: 285/3027, Total:   0.054784,   L-x:  6.39%,   L-y:  8.26%,   L-w: 28.35%,   L-h: 30.19%,   L-noobj: 19.79%,   L-obj:  7.03%\n",
      "train Epoch: 1, Batch: 286/3027, Total:   0.047569,   L-x: 10.03%,   L-y: 10.20%,   L-w: 30.68%,   L-h: 22.08%,   L-noobj: 10.98%,   L-obj: 16.02%\n",
      "train Epoch: 1, Batch: 287/3027, Total:   0.099163,   L-x:  4.92%,   L-y:  8.01%,   L-w: 21.81%,   L-h: 14.96%,   L-noobj: 44.81%,   L-obj:  5.49%\n",
      "train Epoch: 1, Batch: 288/3027, Total:   0.027570,   L-x:  6.25%,   L-y:  9.66%,   L-w: 32.46%,   L-h: 21.10%,   L-noobj: 16.51%,   L-obj: 14.02%\n",
      "train Epoch: 1, Batch: 289/3027, Total:   0.034490,   L-x:  6.52%,   L-y:  7.28%,   L-w: 26.20%,   L-h: 22.31%,   L-noobj: 26.14%,   L-obj: 11.55%\n",
      "train Epoch: 1, Batch: 290/3027, Total:   0.026276,   L-x:  6.66%,   L-y:  7.01%,   L-w: 29.00%,   L-h: 25.62%,   L-noobj: 18.73%,   L-obj: 12.97%\n",
      "train Epoch: 1, Batch: 291/3027, Total:   0.381974,   L-x:  1.01%,   L-y:  1.52%,   L-w: 35.83%,   L-h: 38.06%,   L-noobj: 21.31%,   L-obj:  2.27%\n",
      "train Epoch: 1, Batch: 292/3027, Total:   0.206312,   L-x:  1.59%,   L-y:  2.00%,   L-w: 24.14%,   L-h: 26.52%,   L-noobj: 42.24%,   L-obj:  3.51%\n",
      "train Epoch: 1, Batch: 293/3027, Total:   0.023716,   L-x: 11.80%,   L-y: 12.02%,   L-w: 26.05%,   L-h: 24.15%,   L-noobj: 12.52%,   L-obj: 13.46%\n",
      "train Epoch: 1, Batch: 294/3027, Total:   0.726921,   L-x:  0.85%,   L-y:  0.53%,   L-w: 42.56%,   L-h: 43.86%,   L-noobj: 11.36%,   L-obj:  0.85%\n",
      "train Epoch: 1, Batch: 295/3027, Total:   0.050243,   L-x:  7.00%,   L-y:  7.40%,   L-w: 28.32%,   L-h: 32.85%,   L-noobj: 15.03%,   L-obj:  9.41%\n",
      "train Epoch: 1, Batch: 296/3027, Total:   0.026818,   L-x: 11.01%,   L-y: 11.84%,   L-w: 24.83%,   L-h: 25.35%,   L-noobj: 15.11%,   L-obj: 11.86%\n",
      "train Epoch: 1, Batch: 297/3027, Total:   0.020881,   L-x:  9.93%,   L-y: 11.90%,   L-w: 24.13%,   L-h: 22.66%,   L-noobj: 21.07%,   L-obj: 10.31%\n",
      "train Epoch: 1, Batch: 298/3027, Total:   0.035569,   L-x: 13.46%,   L-y: 11.97%,   L-w: 18.87%,   L-h: 24.16%,   L-noobj: 19.24%,   L-obj: 12.29%\n",
      "train Epoch: 1, Batch: 299/3027, Total:   0.032180,   L-x:  7.73%,   L-y:  9.19%,   L-w: 37.55%,   L-h: 19.89%,   L-noobj: 10.29%,   L-obj: 15.34%\n",
      "train Epoch: 1, Batch: 300/3027, Total:   0.427730,   L-x:  1.59%,   L-y:  1.23%,   L-w: 42.17%,   L-h: 37.50%,   L-noobj: 16.69%,   L-obj:  0.82%\n",
      "train Epoch: 1, Batch: 301/3027, Total:   0.100697,   L-x:  7.71%,   L-y: 12.64%,   L-w: 30.16%,   L-h: 26.82%,   L-noobj: 11.10%,   L-obj: 11.57%\n",
      "train Epoch: 1, Batch: 302/3027, Total:   0.045678,   L-x:  8.71%,   L-y: 16.58%,   L-w: 25.00%,   L-h: 21.64%,   L-noobj: 20.37%,   L-obj:  7.70%\n",
      "train Epoch: 1, Batch: 303/3027, Total:   0.014160,   L-x: 12.20%,   L-y: 11.52%,   L-w: 21.55%,   L-h: 24.15%,   L-noobj: 18.18%,   L-obj: 12.40%\n",
      "train Epoch: 1, Batch: 304/3027, Total:   0.094399,   L-x:  2.92%,   L-y:  3.23%,   L-w: 36.74%,   L-h: 31.25%,   L-noobj: 23.66%,   L-obj:  2.19%\n",
      "train Epoch: 1, Batch: 305/3027, Total:   0.215314,   L-x:  2.59%,   L-y:  1.65%,   L-w: 46.49%,   L-h: 32.24%,   L-noobj: 15.58%,   L-obj:  1.45%\n",
      "train Epoch: 1, Batch: 306/3027, Total:   0.035108,   L-x:  7.58%,   L-y: 10.00%,   L-w: 18.08%,   L-h: 19.98%,   L-noobj: 25.47%,   L-obj: 18.89%\n",
      "train Epoch: 1, Batch: 307/3027, Total:   0.056472,   L-x:  6.10%,   L-y:  6.98%,   L-w: 34.54%,   L-h: 26.97%,   L-noobj: 18.75%,   L-obj:  6.65%\n",
      "train Epoch: 1, Batch: 308/3027, Total:   0.034952,   L-x: 13.40%,   L-y: 11.89%,   L-w: 21.16%,   L-h: 21.78%,   L-noobj: 18.92%,   L-obj: 12.85%\n",
      "train Epoch: 1, Batch: 309/3027, Total:   0.364481,   L-x:  1.66%,   L-y:  1.96%,   L-w: 37.21%,   L-h: 32.80%,   L-noobj: 24.28%,   L-obj:  2.09%\n",
      "train Epoch: 1, Batch: 310/3027, Total:   0.057837,   L-x:  4.27%,   L-y:  9.82%,   L-w: 31.40%,   L-h: 18.64%,   L-noobj: 26.84%,   L-obj:  9.04%\n",
      "train Epoch: 1, Batch: 311/3027, Total:   0.034943,   L-x: 10.58%,   L-y:  8.92%,   L-w: 28.08%,   L-h: 19.96%,   L-noobj: 14.82%,   L-obj: 17.65%\n",
      "train Epoch: 1, Batch: 312/3027, Total:   5.378876,   L-x:  0.16%,   L-y:  0.32%,   L-w: 45.43%,   L-h: 47.17%,   L-noobj:  6.74%,   L-obj:  0.18%\n",
      "train Epoch: 1, Batch: 313/3027, Total:   0.031447,   L-x: 11.76%,   L-y:  9.57%,   L-w: 19.48%,   L-h: 18.99%,   L-noobj: 28.22%,   L-obj: 11.97%\n",
      "train Epoch: 1, Batch: 314/3027, Total:   0.041847,   L-x:  8.90%,   L-y:  8.42%,   L-w: 19.71%,   L-h: 12.90%,   L-noobj: 41.04%,   L-obj:  9.03%\n",
      "train Epoch: 1, Batch: 315/3027, Total:   0.044899,   L-x:  6.42%,   L-y:  6.81%,   L-w: 28.21%,   L-h: 25.88%,   L-noobj: 28.75%,   L-obj:  3.93%\n",
      "train Epoch: 1, Batch: 316/3027, Total:   0.028827,   L-x:  8.19%,   L-y:  7.25%,   L-w: 25.52%,   L-h: 17.11%,   L-noobj: 32.34%,   L-obj:  9.61%\n",
      "train Epoch: 1, Batch: 317/3027, Total:   0.054605,   L-x:  9.23%,   L-y:  9.22%,   L-w: 20.68%,   L-h: 15.16%,   L-noobj: 42.08%,   L-obj:  3.63%\n",
      "train Epoch: 1, Batch: 318/3027, Total:   0.055078,   L-x: 10.00%,   L-y:  9.05%,   L-w: 18.21%,   L-h: 19.73%,   L-noobj: 38.10%,   L-obj:  4.91%\n",
      "train Epoch: 1, Batch: 319/3027, Total:   0.025429,   L-x: 12.06%,   L-y:  6.80%,   L-w: 27.06%,   L-h: 21.52%,   L-noobj: 23.11%,   L-obj:  9.45%\n",
      "train Epoch: 1, Batch: 320/3027, Total:   0.033827,   L-x:  8.03%,   L-y:  6.02%,   L-w: 28.32%,   L-h: 36.54%,   L-noobj: 14.13%,   L-obj:  6.96%\n",
      "train Epoch: 1, Batch: 321/3027, Total:   0.036842,   L-x:  6.03%,   L-y: 14.29%,   L-w: 28.42%,   L-h: 22.19%,   L-noobj: 21.59%,   L-obj:  7.50%\n",
      "train Epoch: 1, Batch: 322/3027, Total:   0.035997,   L-x: 10.09%,   L-y: 11.10%,   L-w: 24.24%,   L-h: 27.94%,   L-noobj: 19.96%,   L-obj:  6.66%\n",
      "train Epoch: 1, Batch: 323/3027, Total:   0.060214,   L-x:  8.98%,   L-y: 11.82%,   L-w: 23.16%,   L-h: 17.37%,   L-noobj: 26.63%,   L-obj: 12.04%\n",
      "train Epoch: 1, Batch: 324/3027, Total:   0.030215,   L-x: 10.50%,   L-y: 13.08%,   L-w: 21.29%,   L-h: 19.28%,   L-noobj: 28.33%,   L-obj:  7.51%\n",
      "train Epoch: 1, Batch: 325/3027, Total:   0.028737,   L-x: 12.73%,   L-y:  9.61%,   L-w: 21.18%,   L-h: 17.49%,   L-noobj: 29.55%,   L-obj:  9.44%\n",
      "train Epoch: 1, Batch: 326/3027, Total:   0.050746,   L-x:  7.17%,   L-y:  6.66%,   L-w: 31.47%,   L-h: 21.23%,   L-noobj: 26.47%,   L-obj:  7.00%\n",
      "train Epoch: 1, Batch: 327/3027, Total:   0.036218,   L-x:  9.99%,   L-y:  6.78%,   L-w: 27.46%,   L-h: 22.27%,   L-noobj: 23.09%,   L-obj: 10.40%\n",
      "train Epoch: 1, Batch: 328/3027, Total:   0.016247,   L-x:  8.74%,   L-y:  8.60%,   L-w: 27.83%,   L-h: 22.78%,   L-noobj: 21.35%,   L-obj: 10.69%\n",
      "train Epoch: 1, Batch: 329/3027, Total:   0.063978,   L-x:  7.17%,   L-y: 13.36%,   L-w: 27.35%,   L-h: 20.76%,   L-noobj: 23.04%,   L-obj:  8.31%\n",
      "train Epoch: 1, Batch: 330/3027, Total:   0.038440,   L-x: 15.67%,   L-y:  8.91%,   L-w: 20.23%,   L-h: 20.85%,   L-noobj: 23.85%,   L-obj: 10.49%\n",
      "train Epoch: 1, Batch: 331/3027, Total:   0.035442,   L-x: 11.41%,   L-y:  7.32%,   L-w: 29.39%,   L-h: 21.64%,   L-noobj: 22.14%,   L-obj:  8.10%\n",
      "train Epoch: 1, Batch: 332/3027, Total:   0.039336,   L-x:  8.19%,   L-y:  8.51%,   L-w: 22.77%,   L-h: 27.10%,   L-noobj: 23.39%,   L-obj: 10.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 333/3027, Total:   0.046408,   L-x:  7.35%,   L-y:  7.81%,   L-w: 29.91%,   L-h: 24.66%,   L-noobj: 22.22%,   L-obj:  8.05%\n",
      "train Epoch: 1, Batch: 334/3027, Total:   0.024104,   L-x: 10.51%,   L-y:  9.81%,   L-w: 21.40%,   L-h: 19.07%,   L-noobj: 29.22%,   L-obj:  9.99%\n",
      "train Epoch: 1, Batch: 335/3027, Total:   0.064102,   L-x:  8.89%,   L-y: 13.71%,   L-w: 23.16%,   L-h: 14.88%,   L-noobj: 28.70%,   L-obj: 10.66%\n",
      "train Epoch: 1, Batch: 336/3027, Total:  53.450890,   L-x:  0.01%,   L-y:  0.02%,   L-w: 49.44%,   L-h: 50.09%,   L-noobj:  0.43%,   L-obj:  0.02%\n",
      "train Epoch: 1, Batch: 337/3027, Total:   2.868995,   L-x:  0.22%,   L-y:  0.27%,   L-w: 49.04%,   L-h: 49.37%,   L-noobj:  1.00%,   L-obj:  0.11%\n",
      "train Epoch: 1, Batch: 338/3027, Total:   0.027051,   L-x:  8.71%,   L-y:  6.06%,   L-w: 25.32%,   L-h: 22.86%,   L-noobj: 28.36%,   L-obj:  8.68%\n",
      "train Epoch: 1, Batch: 339/3027, Total:   0.046110,   L-x:  4.82%,   L-y:  8.61%,   L-w: 29.75%,   L-h: 25.24%,   L-noobj: 11.51%,   L-obj: 20.07%\n",
      "train Epoch: 1, Batch: 340/3027, Total:   2.597418,   L-x:  0.19%,   L-y:  0.15%,   L-w: 50.05%,   L-h: 48.04%,   L-noobj:  1.37%,   L-obj:  0.18%\n",
      "train Epoch: 1, Batch: 341/3027, Total:   0.076460,   L-x:  4.89%,   L-y: 13.34%,   L-w: 28.24%,   L-h: 19.05%,   L-noobj: 20.48%,   L-obj: 14.00%\n",
      "train Epoch: 1, Batch: 342/3027, Total:   0.082997,   L-x:  6.22%,   L-y:  6.78%,   L-w: 26.88%,   L-h: 28.91%,   L-noobj: 22.18%,   L-obj:  9.02%\n",
      "train Epoch: 1, Batch: 343/3027, Total:   0.061450,   L-x:  7.20%,   L-y: 11.32%,   L-w: 31.04%,   L-h: 22.01%,   L-noobj: 19.35%,   L-obj:  9.08%\n",
      "train Epoch: 1, Batch: 344/3027, Total:   0.071020,   L-x: 14.83%,   L-y:  9.82%,   L-w: 22.37%,   L-h: 31.05%,   L-noobj:  7.66%,   L-obj: 14.26%\n",
      "train Epoch: 1, Batch: 345/3027, Total:   0.590544,   L-x:  0.38%,   L-y:  0.36%,   L-w: 49.26%,   L-h: 46.39%,   L-noobj:  2.92%,   L-obj:  0.69%\n",
      "train Epoch: 1, Batch: 346/3027, Total:   0.032826,   L-x:  6.73%,   L-y:  8.90%,   L-w: 30.25%,   L-h: 29.12%,   L-noobj: 12.92%,   L-obj: 12.09%\n",
      "train Epoch: 1, Batch: 347/3027, Total:   0.661651,   L-x:  0.73%,   L-y:  0.66%,   L-w: 46.06%,   L-h: 45.65%,   L-noobj:  6.20%,   L-obj:  0.71%\n",
      "train Epoch: 1, Batch: 348/3027, Total:   0.049463,   L-x:  6.97%,   L-y:  7.25%,   L-w: 28.81%,   L-h: 22.40%,   L-noobj: 14.85%,   L-obj: 19.72%\n",
      "train Epoch: 1, Batch: 349/3027, Total:   0.083554,   L-x:  6.80%,   L-y: 13.61%,   L-w: 10.58%,   L-h: 44.52%,   L-noobj: 16.32%,   L-obj:  8.17%\n",
      "train Epoch: 1, Batch: 350/3027, Total:   0.028074,   L-x: 12.04%,   L-y: 10.41%,   L-w: 25.53%,   L-h: 25.40%,   L-noobj: 15.50%,   L-obj: 11.12%\n",
      "train Epoch: 1, Batch: 351/3027, Total:   0.065418,   L-x:  8.78%,   L-y:  8.31%,   L-w: 28.91%,   L-h: 26.92%,   L-noobj: 17.71%,   L-obj:  9.36%\n",
      "train Epoch: 1, Batch: 352/3027, Total:   0.059263,   L-x:  6.42%,   L-y:  8.37%,   L-w: 37.85%,   L-h: 23.35%,   L-noobj:  3.20%,   L-obj: 20.81%\n",
      "train Epoch: 1, Batch: 353/3027, Total:   0.049595,   L-x:  6.67%,   L-y:  9.85%,   L-w: 27.07%,   L-h: 21.97%,   L-noobj: 28.64%,   L-obj:  5.80%\n",
      "train Epoch: 1, Batch: 354/3027, Total:   0.053196,   L-x:  6.06%,   L-y:  7.19%,   L-w: 29.44%,   L-h: 25.44%,   L-noobj: 29.03%,   L-obj:  2.84%\n",
      "train Epoch: 1, Batch: 355/3027, Total:   0.122717,   L-x:  7.25%,   L-y:  5.73%,   L-w: 24.12%,   L-h: 28.59%,   L-noobj: 24.73%,   L-obj:  9.58%\n",
      "train Epoch: 1, Batch: 356/3027, Total:   0.097926,   L-x:  9.00%,   L-y:  9.82%,   L-w: 24.31%,   L-h: 18.11%,   L-noobj: 30.97%,   L-obj:  7.79%\n",
      "train Epoch: 1, Batch: 357/3027, Total:   0.358013,   L-x:  0.96%,   L-y:  0.97%,   L-w: 40.75%,   L-h: 49.62%,   L-noobj:  6.44%,   L-obj:  1.26%\n",
      "train Epoch: 1, Batch: 358/3027, Total:   0.044084,   L-x:  7.98%,   L-y:  7.17%,   L-w: 21.23%,   L-h: 31.24%,   L-noobj: 29.25%,   L-obj:  3.14%\n",
      "train Epoch: 1, Batch: 359/3027, Total:   0.024307,   L-x:  8.67%,   L-y:  7.81%,   L-w: 25.71%,   L-h: 27.09%,   L-noobj: 14.20%,   L-obj: 16.52%\n",
      "train Epoch: 1, Batch: 360/3027, Total:   0.037840,   L-x:  8.89%,   L-y: 12.63%,   L-w: 21.45%,   L-h: 22.65%,   L-noobj: 22.52%,   L-obj: 11.86%\n",
      "train Epoch: 1, Batch: 361/3027, Total:   0.160789,   L-x:  3.32%,   L-y:  3.77%,   L-w: 23.96%,   L-h: 49.02%,   L-noobj: 17.25%,   L-obj:  2.69%\n",
      "train Epoch: 1, Batch: 362/3027, Total:   0.045061,   L-x: 15.54%,   L-y: 10.26%,   L-w: 23.79%,   L-h: 20.72%,   L-noobj: 17.46%,   L-obj: 12.24%\n",
      "train Epoch: 1, Batch: 363/3027, Total:   0.119942,   L-x:  2.31%,   L-y:  3.10%,   L-w: 33.83%,   L-h: 40.51%,   L-noobj: 16.98%,   L-obj:  3.27%\n",
      "train Epoch: 1, Batch: 364/3027, Total:   0.221125,   L-x:  1.61%,   L-y:  1.51%,   L-w: 40.76%,   L-h: 40.76%,   L-noobj: 13.66%,   L-obj:  1.69%\n",
      "train Epoch: 1, Batch: 365/3027, Total:   0.058319,   L-x:  6.69%,   L-y:  9.70%,   L-w: 24.61%,   L-h: 26.97%,   L-noobj: 23.52%,   L-obj:  8.50%\n",
      "train Epoch: 1, Batch: 366/3027, Total:   0.090070,   L-x:  3.47%,   L-y:  3.73%,   L-w: 38.33%,   L-h: 35.21%,   L-noobj: 15.97%,   L-obj:  3.29%\n",
      "train Epoch: 1, Batch: 367/3027, Total:   0.027660,   L-x:  6.99%,   L-y:  6.34%,   L-w: 31.56%,   L-h: 28.31%,   L-noobj: 13.15%,   L-obj: 13.66%\n",
      "train Epoch: 1, Batch: 368/3027, Total:   0.043739,   L-x: 10.65%,   L-y:  6.90%,   L-w: 21.33%,   L-h: 23.79%,   L-noobj: 23.64%,   L-obj: 13.68%\n",
      "train Epoch: 1, Batch: 369/3027, Total:   0.041808,   L-x: 11.06%,   L-y: 10.28%,   L-w: 22.57%,   L-h: 32.33%,   L-noobj: 11.57%,   L-obj: 12.19%\n",
      "train Epoch: 1, Batch: 370/3027, Total:   0.033652,   L-x:  9.54%,   L-y:  7.44%,   L-w: 29.22%,   L-h: 25.59%,   L-noobj: 13.29%,   L-obj: 14.92%\n",
      "train Epoch: 1, Batch: 371/3027, Total:   0.365952,   L-x:  1.71%,   L-y:  0.94%,   L-w: 42.47%,   L-h: 37.27%,   L-noobj: 15.31%,   L-obj:  2.30%\n",
      "train Epoch: 1, Batch: 372/3027, Total:   0.678508,   L-x:  0.96%,   L-y:  1.09%,   L-w: 41.93%,   L-h: 40.52%,   L-noobj: 14.11%,   L-obj:  1.39%\n",
      "train Epoch: 1, Batch: 373/3027, Total:   0.026608,   L-x:  8.76%,   L-y:  7.22%,   L-w: 28.37%,   L-h: 26.84%,   L-noobj: 17.68%,   L-obj: 11.13%\n",
      "train Epoch: 1, Batch: 374/3027, Total:   0.033341,   L-x: 10.91%,   L-y:  6.87%,   L-w: 23.75%,   L-h: 23.52%,   L-noobj: 19.97%,   L-obj: 14.97%\n",
      "train Epoch: 1, Batch: 375/3027, Total:   0.037317,   L-x:  7.72%,   L-y:  9.05%,   L-w: 26.36%,   L-h: 21.83%,   L-noobj: 29.16%,   L-obj:  5.88%\n",
      "train Epoch: 1, Batch: 376/3027, Total:   0.044504,   L-x:  6.65%,   L-y: 15.33%,   L-w: 24.46%,   L-h: 23.04%,   L-noobj: 21.99%,   L-obj:  8.53%\n",
      "train Epoch: 1, Batch: 377/3027, Total:   0.037707,   L-x:  7.16%,   L-y:  8.59%,   L-w: 21.48%,   L-h: 27.32%,   L-noobj: 28.11%,   L-obj:  7.34%\n",
      "train Epoch: 1, Batch: 378/3027, Total:   0.023258,   L-x: 11.19%,   L-y:  9.61%,   L-w: 30.04%,   L-h: 21.32%,   L-noobj: 17.48%,   L-obj: 10.36%\n",
      "train Epoch: 1, Batch: 379/3027, Total:   2.707560,   L-x:  0.12%,   L-y:  0.19%,   L-w: 46.91%,   L-h: 49.57%,   L-noobj:  2.99%,   L-obj:  0.23%\n",
      "train Epoch: 1, Batch: 380/3027, Total:   0.048988,   L-x:  5.51%,   L-y:  8.26%,   L-w: 25.08%,   L-h: 29.97%,   L-noobj: 23.42%,   L-obj:  7.76%\n",
      "train Epoch: 1, Batch: 381/3027, Total:   0.162947,   L-x:  1.45%,   L-y:  2.69%,   L-w: 37.22%,   L-h: 40.94%,   L-noobj: 15.43%,   L-obj:  2.26%\n",
      "train Epoch: 1, Batch: 382/3027, Total:   0.036573,   L-x: 11.66%,   L-y: 12.40%,   L-w: 21.13%,   L-h: 25.64%,   L-noobj: 23.24%,   L-obj:  5.94%\n",
      "train Epoch: 1, Batch: 383/3027, Total:   0.143942,   L-x:  2.23%,   L-y:  2.84%,   L-w: 34.23%,   L-h: 40.27%,   L-noobj: 18.33%,   L-obj:  2.10%\n",
      "train Epoch: 1, Batch: 384/3027, Total:   0.334366,   L-x:  0.80%,   L-y:  1.52%,   L-w: 41.76%,   L-h: 45.31%,   L-noobj:  9.46%,   L-obj:  1.15%\n",
      "train Epoch: 1, Batch: 385/3027, Total:   0.053575,   L-x:  8.17%,   L-y: 10.38%,   L-w: 19.59%,   L-h: 23.33%,   L-noobj: 27.62%,   L-obj: 10.90%\n",
      "train Epoch: 1, Batch: 386/3027, Total:   0.032350,   L-x:  7.14%,   L-y: 10.02%,   L-w: 26.19%,   L-h: 19.92%,   L-noobj: 22.89%,   L-obj: 13.83%\n",
      "train Epoch: 1, Batch: 387/3027, Total:   0.041850,   L-x:  5.88%,   L-y:  6.82%,   L-w: 29.87%,   L-h: 19.33%,   L-noobj: 29.29%,   L-obj:  8.81%\n",
      "train Epoch: 1, Batch: 388/3027, Total:   0.227255,   L-x:  1.79%,   L-y:  2.64%,   L-w: 40.67%,   L-h: 47.26%,   L-noobj:  6.16%,   L-obj:  1.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 389/3027, Total:   0.027310,   L-x: 11.69%,   L-y: 10.31%,   L-w: 24.48%,   L-h: 16.01%,   L-noobj: 24.26%,   L-obj: 13.25%\n",
      "train Epoch: 1, Batch: 390/3027, Total:   0.923151,   L-x:  0.64%,   L-y:  0.38%,   L-w: 47.14%,   L-h: 48.03%,   L-noobj:  3.43%,   L-obj:  0.38%\n",
      "train Epoch: 1, Batch: 391/3027, Total:   0.025775,   L-x:  8.23%,   L-y:  9.45%,   L-w: 27.80%,   L-h: 28.34%,   L-noobj: 18.76%,   L-obj:  7.41%\n",
      "train Epoch: 1, Batch: 392/3027, Total:   0.064494,   L-x:  5.93%,   L-y:  8.05%,   L-w: 23.65%,   L-h: 27.83%,   L-noobj: 27.27%,   L-obj:  7.28%\n",
      "train Epoch: 1, Batch: 393/3027, Total:   1.070898,   L-x:  0.36%,   L-y:  0.39%,   L-w: 47.59%,   L-h: 48.62%,   L-noobj:  2.71%,   L-obj:  0.33%\n",
      "train Epoch: 1, Batch: 394/3027, Total:   2.444996,   L-x:  0.30%,   L-y:  0.43%,   L-w: 47.55%,   L-h: 48.94%,   L-noobj:  2.49%,   L-obj:  0.29%\n",
      "train Epoch: 1, Batch: 395/3027, Total:   0.404301,   L-x:  1.21%,   L-y:  1.14%,   L-w: 40.85%,   L-h: 43.06%,   L-noobj: 12.37%,   L-obj:  1.37%\n",
      "train Epoch: 1, Batch: 396/3027, Total:   0.037421,   L-x: 11.33%,   L-y: 15.21%,   L-w: 19.77%,   L-h: 24.89%,   L-noobj: 19.16%,   L-obj:  9.65%\n",
      "train Epoch: 1, Batch: 397/3027, Total:   0.034893,   L-x:  7.25%,   L-y: 11.85%,   L-w: 21.97%,   L-h: 29.95%,   L-noobj: 18.08%,   L-obj: 10.90%\n",
      "train Epoch: 1, Batch: 398/3027, Total:   0.060134,   L-x: 16.29%,   L-y: 11.49%,   L-w: 25.66%,   L-h: 22.16%,   L-noobj: 14.74%,   L-obj:  9.65%\n",
      "train Epoch: 1, Batch: 399/3027, Total:   0.071011,   L-x: 14.74%,   L-y:  9.33%,   L-w: 15.92%,   L-h: 28.87%,   L-noobj: 18.72%,   L-obj: 12.42%\n",
      "train Epoch: 1, Batch: 400/3027, Total:   0.070940,   L-x:  3.15%,   L-y:  5.45%,   L-w: 27.63%,   L-h: 29.95%,   L-noobj: 30.17%,   L-obj:  3.64%\n",
      "train Epoch: 1, Batch: 401/3027, Total:   0.049891,   L-x:  3.59%,   L-y:  3.79%,   L-w: 27.85%,   L-h: 25.12%,   L-noobj: 34.17%,   L-obj:  5.47%\n",
      "train Epoch: 1, Batch: 402/3027, Total:   0.028332,   L-x: 13.42%,   L-y: 14.70%,   L-w: 21.30%,   L-h: 18.08%,   L-noobj: 19.87%,   L-obj: 12.62%\n",
      "train Epoch: 1, Batch: 403/3027, Total:   0.027104,   L-x:  9.81%,   L-y:  8.03%,   L-w: 25.56%,   L-h: 24.72%,   L-noobj: 27.13%,   L-obj:  4.76%\n",
      "train Epoch: 1, Batch: 404/3027, Total:   0.137787,   L-x:  2.53%,   L-y:  4.25%,   L-w: 31.87%,   L-h: 40.57%,   L-noobj: 18.13%,   L-obj:  2.65%\n",
      "train Epoch: 1, Batch: 405/3027, Total:   0.063170,   L-x:  6.45%,   L-y:  6.89%,   L-w: 28.52%,   L-h: 24.74%,   L-noobj: 26.31%,   L-obj:  7.10%\n",
      "train Epoch: 1, Batch: 406/3027, Total:   0.076032,   L-x:  5.82%,   L-y:  4.14%,   L-w: 40.49%,   L-h: 27.80%,   L-noobj: 17.29%,   L-obj:  4.46%\n",
      "train Epoch: 1, Batch: 407/3027, Total:   0.022078,   L-x: 11.84%,   L-y: 11.12%,   L-w: 27.21%,   L-h: 19.20%,   L-noobj: 19.31%,   L-obj: 11.32%\n",
      "train Epoch: 1, Batch: 408/3027, Total:   0.032118,   L-x: 10.45%,   L-y:  8.33%,   L-w: 30.49%,   L-h: 22.48%,   L-noobj: 18.10%,   L-obj: 10.14%\n",
      "train Epoch: 1, Batch: 409/3027, Total:   0.048322,   L-x:  4.40%,   L-y:  9.18%,   L-w: 27.16%,   L-h: 23.60%,   L-noobj: 28.27%,   L-obj:  7.40%\n",
      "train Epoch: 1, Batch: 410/3027, Total:   0.018294,   L-x: 11.66%,   L-y:  9.37%,   L-w: 25.63%,   L-h: 20.04%,   L-noobj: 20.66%,   L-obj: 12.64%\n",
      "train Epoch: 1, Batch: 411/3027, Total:   0.045967,   L-x:  8.08%,   L-y: 12.49%,   L-w: 34.98%,   L-h: 22.12%,   L-noobj: 12.08%,   L-obj: 10.23%\n",
      "train Epoch: 1, Batch: 412/3027, Total:   1.339681,   L-x:  0.36%,   L-y:  0.32%,   L-w: 47.83%,   L-h: 49.20%,   L-noobj:  2.10%,   L-obj:  0.19%\n",
      "train Epoch: 1, Batch: 413/3027, Total:   0.024736,   L-x: 11.72%,   L-y:  9.00%,   L-w: 25.77%,   L-h: 23.40%,   L-noobj: 14.74%,   L-obj: 15.36%\n",
      "train Epoch: 1, Batch: 414/3027, Total:   0.457750,   L-x:  0.53%,   L-y:  1.22%,   L-w: 43.21%,   L-h: 43.81%,   L-noobj: 10.31%,   L-obj:  0.92%\n",
      "train Epoch: 1, Batch: 415/3027, Total:   0.020060,   L-x:  9.61%,   L-y: 10.28%,   L-w: 22.44%,   L-h: 22.49%,   L-noobj: 11.52%,   L-obj: 23.67%\n",
      "train Epoch: 1, Batch: 416/3027, Total:   0.037081,   L-x:  9.50%,   L-y:  9.85%,   L-w: 22.98%,   L-h: 20.00%,   L-noobj: 28.87%,   L-obj:  8.80%\n",
      "train Epoch: 1, Batch: 417/3027, Total:   0.032160,   L-x:  9.50%,   L-y: 16.98%,   L-w: 23.76%,   L-h: 18.34%,   L-noobj: 22.39%,   L-obj:  9.04%\n",
      "train Epoch: 1, Batch: 418/3027, Total:   0.018615,   L-x: 10.53%,   L-y: 10.50%,   L-w: 23.56%,   L-h: 28.46%,   L-noobj: 15.53%,   L-obj: 11.42%\n",
      "train Epoch: 1, Batch: 419/3027, Total:   0.087172,   L-x:  5.59%,   L-y:  8.77%,   L-w: 33.00%,   L-h: 26.38%,   L-noobj: 22.63%,   L-obj:  3.63%\n",
      "train Epoch: 1, Batch: 420/3027, Total:   0.034046,   L-x:  9.23%,   L-y: 11.53%,   L-w: 22.56%,   L-h: 23.74%,   L-noobj: 25.41%,   L-obj:  7.53%\n",
      "train Epoch: 1, Batch: 421/3027, Total:   0.022995,   L-x:  6.74%,   L-y:  7.47%,   L-w: 28.39%,   L-h: 21.92%,   L-noobj: 25.74%,   L-obj:  9.75%\n",
      "train Epoch: 1, Batch: 422/3027, Total:   0.039633,   L-x:  6.82%,   L-y: 13.32%,   L-w: 26.71%,   L-h: 24.75%,   L-noobj: 18.97%,   L-obj:  9.44%\n",
      "train Epoch: 1, Batch: 423/3027, Total:   1.253292,   L-x:  0.29%,   L-y:  0.78%,   L-w: 44.19%,   L-h: 45.06%,   L-noobj:  8.79%,   L-obj:  0.89%\n",
      "train Epoch: 1, Batch: 424/3027, Total:   0.034178,   L-x: 11.02%,   L-y: 10.90%,   L-w: 27.58%,   L-h: 23.49%,   L-noobj: 19.62%,   L-obj:  7.39%\n",
      "train Epoch: 1, Batch: 425/3027, Total:   0.068964,   L-x:  2.89%,   L-y:  2.61%,   L-w: 40.10%,   L-h: 40.99%,   L-noobj: 11.71%,   L-obj:  1.71%\n",
      "train Epoch: 1, Batch: 426/3027, Total:   0.020488,   L-x: 12.37%,   L-y: 14.71%,   L-w: 22.78%,   L-h: 14.84%,   L-noobj: 20.21%,   L-obj: 15.10%\n",
      "train Epoch: 1, Batch: 427/3027, Total:   0.084506,   L-x:  6.30%,   L-y:  6.18%,   L-w: 32.82%,   L-h: 29.56%,   L-noobj: 22.01%,   L-obj:  3.13%\n",
      "train Epoch: 1, Batch: 428/3027, Total:   0.022507,   L-x: 14.50%,   L-y: 12.68%,   L-w: 22.87%,   L-h: 15.76%,   L-noobj: 20.30%,   L-obj: 13.90%\n",
      "train Epoch: 1, Batch: 429/3027, Total:   0.033870,   L-x: 10.94%,   L-y: 14.26%,   L-w: 24.56%,   L-h: 24.91%,   L-noobj: 14.18%,   L-obj: 11.16%\n",
      "train Epoch: 1, Batch: 430/3027, Total:   0.048480,   L-x:  8.37%,   L-y:  9.98%,   L-w: 22.52%,   L-h: 22.54%,   L-noobj: 28.32%,   L-obj:  8.26%\n",
      "train Epoch: 1, Batch: 431/3027, Total:   0.033719,   L-x: 11.08%,   L-y: 13.09%,   L-w: 27.82%,   L-h: 19.93%,   L-noobj: 18.27%,   L-obj:  9.81%\n",
      "train Epoch: 1, Batch: 432/3027, Total:   0.047635,   L-x:  5.33%,   L-y: 12.76%,   L-w: 27.46%,   L-h: 27.25%,   L-noobj: 19.93%,   L-obj:  7.28%\n",
      "train Epoch: 1, Batch: 433/3027, Total:   0.021417,   L-x:  9.39%,   L-y: 10.69%,   L-w: 25.75%,   L-h: 17.90%,   L-noobj: 14.26%,   L-obj: 22.01%\n",
      "train Epoch: 1, Batch: 434/3027, Total:   0.027396,   L-x: 10.13%,   L-y: 10.83%,   L-w: 20.49%,   L-h: 19.55%,   L-noobj: 23.81%,   L-obj: 15.20%\n",
      "train Epoch: 1, Batch: 435/3027, Total:   0.018723,   L-x:  8.86%,   L-y: 10.39%,   L-w: 22.13%,   L-h: 23.35%,   L-noobj: 15.86%,   L-obj: 19.40%\n",
      "train Epoch: 1, Batch: 436/3027, Total:   0.037540,   L-x:  8.57%,   L-y: 12.13%,   L-w: 20.45%,   L-h: 20.58%,   L-noobj: 25.64%,   L-obj: 12.63%\n",
      "train Epoch: 1, Batch: 437/3027, Total:   0.028881,   L-x: 13.81%,   L-y: 10.83%,   L-w: 23.20%,   L-h: 17.21%,   L-noobj: 16.11%,   L-obj: 18.84%\n",
      "train Epoch: 1, Batch: 438/3027, Total:   0.041413,   L-x: 10.13%,   L-y: 10.22%,   L-w: 25.44%,   L-h: 17.70%,   L-noobj: 23.33%,   L-obj: 13.18%\n",
      "train Epoch: 1, Batch: 439/3027, Total:   0.026521,   L-x:  9.37%,   L-y: 11.25%,   L-w: 26.44%,   L-h: 21.18%,   L-noobj: 21.18%,   L-obj: 10.59%\n",
      "train Epoch: 1, Batch: 440/3027, Total:   0.037783,   L-x: 11.62%,   L-y: 10.96%,   L-w: 24.93%,   L-h: 26.32%,   L-noobj: 17.46%,   L-obj:  8.70%\n",
      "train Epoch: 1, Batch: 441/3027, Total:   0.022980,   L-x:  9.90%,   L-y: 10.73%,   L-w: 26.09%,   L-h: 24.82%,   L-noobj: 19.41%,   L-obj:  9.05%\n",
      "train Epoch: 1, Batch: 442/3027, Total:   0.094927,   L-x:  4.02%,   L-y:  3.50%,   L-w: 27.85%,   L-h: 29.17%,   L-noobj: 30.55%,   L-obj:  4.91%\n",
      "train Epoch: 1, Batch: 443/3027, Total:   0.015331,   L-x: 14.46%,   L-y: 10.80%,   L-w: 25.57%,   L-h: 17.09%,   L-noobj: 12.02%,   L-obj: 20.06%\n",
      "train Epoch: 1, Batch: 444/3027, Total:   0.033260,   L-x: 12.54%,   L-y: 14.42%,   L-w: 21.15%,   L-h: 19.15%,   L-noobj: 22.18%,   L-obj: 10.56%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Epoch: 1, Batch: 445/3027, Total:   0.044812,   L-x: 12.58%,   L-y: 16.76%,   L-w: 19.79%,   L-h: 15.04%,   L-noobj: 19.78%,   L-obj: 16.06%\n",
      "train Epoch: 1, Batch: 446/3027, Total:   0.029001,   L-x:  9.79%,   L-y: 11.99%,   L-w: 26.69%,   L-h: 25.01%,   L-noobj: 13.54%,   L-obj: 12.97%\n",
      "train Epoch: 1, Batch: 447/3027, Total:   0.062081,   L-x:  4.58%,   L-y:  5.51%,   L-w: 38.98%,   L-h: 34.73%,   L-noobj: 11.67%,   L-obj:  4.54%\n",
      "train Epoch: 1, Batch: 448/3027, Total:   0.079656,   L-x: 10.97%,   L-y:  9.90%,   L-w: 19.39%,   L-h: 16.64%,   L-noobj: 38.16%,   L-obj:  4.93%\n",
      "train Epoch: 1, Batch: 449/3027, Total:   0.022862,   L-x:  9.72%,   L-y:  9.21%,   L-w: 24.65%,   L-h: 18.48%,   L-noobj: 24.10%,   L-obj: 13.84%\n",
      "train Epoch: 1, Batch: 450/3027, Total:   0.032049,   L-x: 14.05%,   L-y: 16.78%,   L-w: 25.03%,   L-h: 22.83%,   L-noobj: 12.08%,   L-obj:  9.22%\n",
      "train Epoch: 1, Batch: 451/3027, Total:   0.075659,   L-x:  5.15%,   L-y:  3.70%,   L-w: 28.53%,   L-h: 22.13%,   L-noobj: 35.73%,   L-obj:  4.76%\n",
      "train Epoch: 1, Batch: 452/3027, Total:   0.029221,   L-x:  7.82%,   L-y: 12.33%,   L-w: 24.68%,   L-h: 22.70%,   L-noobj: 21.11%,   L-obj: 11.36%\n",
      "train Epoch: 1, Batch: 453/3027, Total:   0.060683,   L-x: 10.30%,   L-y:  7.33%,   L-w: 23.03%,   L-h: 22.31%,   L-noobj: 30.53%,   L-obj:  6.50%\n",
      "train Epoch: 1, Batch: 454/3027, Total:   0.036352,   L-x: 15.43%,   L-y: 12.00%,   L-w: 24.28%,   L-h: 20.73%,   L-noobj: 13.86%,   L-obj: 13.70%\n",
      "train Epoch: 1, Batch: 455/3027, Total:   0.030020,   L-x:  9.33%,   L-y:  8.23%,   L-w: 22.91%,   L-h: 26.37%,   L-noobj: 16.25%,   L-obj: 16.92%\n",
      "train Epoch: 1, Batch: 456/3027, Total:   0.032036,   L-x: 10.39%,   L-y: 12.34%,   L-w: 21.62%,   L-h: 19.11%,   L-noobj: 22.36%,   L-obj: 14.17%\n",
      "train Epoch: 1, Batch: 457/3027, Total:   0.020138,   L-x: 12.80%,   L-y:  9.81%,   L-w: 22.05%,   L-h: 17.85%,   L-noobj: 16.80%,   L-obj: 20.69%\n",
      "train Epoch: 1, Batch: 458/3027, Total:   0.039865,   L-x:  4.89%,   L-y: 10.63%,   L-w: 31.43%,   L-h: 19.26%,   L-noobj: 24.89%,   L-obj:  8.90%\n",
      "train Epoch: 1, Batch: 459/3027, Total:   0.014016,   L-x: 11.66%,   L-y:  8.06%,   L-w: 28.42%,   L-h: 16.29%,   L-noobj: 15.95%,   L-obj: 19.61%\n",
      "train Epoch: 1, Batch: 460/3027, Total:   0.037496,   L-x:  7.86%,   L-y:  8.22%,   L-w: 22.03%,   L-h: 22.78%,   L-noobj: 29.60%,   L-obj:  9.52%\n",
      "train Epoch: 1, Batch: 461/3027, Total:   0.095423,   L-x:  5.88%,   L-y: 15.12%,   L-w: 32.66%,   L-h: 16.09%,   L-noobj: 20.90%,   L-obj:  9.35%\n",
      "train Epoch: 1, Batch: 462/3027, Total:   0.013745,   L-x: 11.46%,   L-y:  8.03%,   L-w: 27.88%,   L-h: 23.52%,   L-noobj: 13.36%,   L-obj: 15.74%\n",
      "train Epoch: 1, Batch: 463/3027, Total:   0.015641,   L-x: 10.20%,   L-y: 10.74%,   L-w: 23.73%,   L-h: 22.66%,   L-noobj: 21.86%,   L-obj: 10.82%\n",
      "train Epoch: 1, Batch: 464/3027, Total:   0.027492,   L-x: 10.54%,   L-y:  8.82%,   L-w: 30.79%,   L-h: 20.37%,   L-noobj: 17.61%,   L-obj: 11.88%\n",
      "train Epoch: 1, Batch: 465/3027, Total:   0.033266,   L-x:  9.13%,   L-y: 10.20%,   L-w: 16.66%,   L-h: 25.45%,   L-noobj: 30.34%,   L-obj:  8.23%\n",
      "train Epoch: 1, Batch: 466/3027, Total:   0.104783,   L-x:  5.73%,   L-y:  5.33%,   L-w:  8.83%,   L-h:  9.64%,   L-noobj: 63.59%,   L-obj:  6.90%\n",
      "train Epoch: 1, Batch: 467/3027, Total:   0.027934,   L-x:  7.74%,   L-y:  7.54%,   L-w: 21.55%,   L-h: 24.23%,   L-noobj: 24.93%,   L-obj: 14.02%\n",
      "train Epoch: 1, Batch: 468/3027, Total:   0.046081,   L-x:  6.21%,   L-y: 10.35%,   L-w: 21.25%,   L-h: 28.41%,   L-noobj: 24.49%,   L-obj:  9.29%\n",
      "train Epoch: 1, Batch: 469/3027, Total:   0.016727,   L-x: 16.18%,   L-y: 11.64%,   L-w: 17.57%,   L-h: 16.21%,   L-noobj: 27.95%,   L-obj: 10.45%\n",
      "train Epoch: 1, Batch: 470/3027, Total:   0.040111,   L-x: 13.84%,   L-y:  9.90%,   L-w: 19.59%,   L-h: 28.45%,   L-noobj: 17.35%,   L-obj: 10.87%\n",
      "train Epoch: 1, Batch: 471/3027, Total:   0.135656,   L-x:  5.62%,   L-y:  5.43%,   L-w: 16.63%,   L-h: 17.36%,   L-noobj: 51.93%,   L-obj:  3.02%\n",
      "train Epoch: 1, Batch: 472/3027, Total:   0.032693,   L-x: 14.13%,   L-y: 12.96%,   L-w: 20.47%,   L-h: 19.33%,   L-noobj: 13.04%,   L-obj: 20.07%\n",
      "train Epoch: 1, Batch: 473/3027, Total:   0.050700,   L-x: 19.46%,   L-y: 16.24%,   L-w: 17.19%,   L-h: 16.84%,   L-noobj: 15.96%,   L-obj: 14.31%\n",
      "train Epoch: 1, Batch: 474/3027, Total:   0.028031,   L-x: 11.54%,   L-y: 13.05%,   L-w: 20.80%,   L-h: 21.84%,   L-noobj: 20.76%,   L-obj: 12.02%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4d17ca4b2b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m         run_epoch(label_prefix=\"train\", data_loader=train_data_loader, epoch=epoch,\n\u001b[1;32m    114\u001b[0m                     \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                     optimizer=optimizer)\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Completed epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Update best loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-a3f31202f42d>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(label_prefix, data_loader, num_steps, optimizer, model, epoch, num_epochs, step)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabel_prefix\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/test/MIT-Driverless-CV-TrainingInfra/CVC-YOLOv3/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, targets)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodule_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_defs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"convolutional\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"upsample\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxpool\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmodule_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"route\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mlayer_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_def\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"layers\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_arguments = list(locals().items())\n",
    "\n",
    "print(\"Initializing model\")\n",
    "model = Darknet(config_path=model_cfg,xy_loss=xy_loss,wh_loss=wh_loss,no_object_loss=no_object_loss,object_loss=object_loss,vanilla_anchor=vanilla_anchor)\n",
    "img_width, img_height = model.img_size()\n",
    "bw  = model.get_bw()\n",
    "validate_uri, train_uri = model.get_links()\n",
    "\n",
    "if output_path == \"automatic\":\n",
    "    current_month = datetime.now().strftime('%B').lower()\n",
    "    current_year = str(datetime.now().year)\n",
    "    if not os.path.exists(os.path.join('outputs/', current_month + '-' + current_year + '-experiments/' + model_cfg.split('.')[0].split('/')[-1])):\n",
    "        os.makedirs(os.path.join('outputs/', current_month + '-' + current_year + '-experiments/' + model_cfg.split('.')[0].split('/')[-1]))\n",
    "    output_uri = os.path.join('outputs/', current_month + '-' + current_year + '-experiments/' + model_cfg.split('.')[0].split('/')[-1])\n",
    "else:\n",
    "    output_uri = output_path\n",
    "\n",
    "num_validate_images, num_train_images = model.num_images()\n",
    "conf_thresh, nms_thresh, iou_thresh = model.get_threshs()\n",
    "num_classes = model.get_num_classes()\n",
    "loss_constant = model.get_loss_constant()\n",
    "conv_activation = model.get_conv_activation()\n",
    "anchors = model.get_anchors()\n",
    "onnx_name = model.get_onnx_name()\n",
    "\n",
    "with tempfile.TemporaryDirectory() as tensorboard_data_dir:\n",
    "    print(\"Initializing data loaders\")\n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        ImageLabelDataset(train_uri, dataset_path=dataset_path, width=img_width, height=img_height, augment_hsv=augment_hsv,\n",
    "                            augment_affine=augment_affine, num_images=num_train_images,\n",
    "                            bw=bw, n_cpu=num_cpu, lr_flip=lr_flip, ud_flip=ud_flip,vis_batch=vis_batch,data_aug=data_aug,blur=blur,salt=salt,noise=noise,contrast=contrast,sharpen=sharpen,ts=ts,debug_mode=debug_mode, upload_dataset=upload_dataset),\n",
    "        batch_size=(1 if debug_mode else batch_size),\n",
    "        shuffle=(False if debug_mode else True),\n",
    "        num_workers=(0 if vis_batch else num_cpu),\n",
    "        pin_memory=cuda)\n",
    "    print(\"Num train images: \", len(train_data_loader.dataset))\n",
    "\n",
    "    validate_data_loader = torch.utils.data.DataLoader(\n",
    "        ImageLabelDataset(validate_uri, dataset_path=dataset_path, width=img_width, height=img_height, augment_hsv=False,\n",
    "                            augment_affine=False, num_images=num_validate_images,\n",
    "                            bw=bw, n_cpu=num_cpu, lr_flip=False, ud_flip=False,vis_batch=vis_batch,data_aug=False,blur=False,salt=False,noise=False,contrast=False,sharpen=False,ts=ts,debug_mode=debug_mode, upload_dataset=upload_dataset),\n",
    "        batch_size=(1 if debug_mode else batch_size),\n",
    "        shuffle=False,\n",
    "        num_workers=(0 if vis_batch else num_cpu),\n",
    "        pin_memory=cuda)\n",
    "    print(\"Num validate images: \", len(validate_data_loader.dataset))\n",
    "\n",
    "    ##### additional configuration #####\n",
    "    print(\"Training batch size: \" + str(batch_size))\n",
    "    \n",
    "    print(\"Checkpoint interval: \" + str(checkpoint_interval))\n",
    "\n",
    "    print(\"Loss constants: \" + str(loss_constant))\n",
    "\n",
    "    print(\"Anchor boxes: \" + str(anchors))\n",
    "\n",
    "    print(\"Training image width: \" + str(img_width))\n",
    "\n",
    "    print(\"Training image height: \" + str(img_height))\n",
    "\n",
    "    print(\"Confidence Threshold: \" + str(conf_thresh))\n",
    "\n",
    "    print(\"Number of training classes: \" + str(num_classes))\n",
    "\n",
    "    print(\"Conv activation type: \" + str(conv_activation))\n",
    "\n",
    "    print(\"Starting learning rate: \" + str(lr))\n",
    "\n",
    "    if ts:\n",
    "        print(\"Tile and scale mode [on]\")\n",
    "    else:\n",
    "        print(\"Tile and scale mode [off]\")\n",
    "\n",
    "    if data_aug:\n",
    "        print(\"Data augmentation mode [on]\")\n",
    "    else:\n",
    "        print(\"Data augmentation mode [off]\")\n",
    "\n",
    "    ####################################\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    weights_path = weights_path\n",
    "    if optimizer_pick == \"Adam\":\n",
    "        print(\"Using Adam Optimizer\")\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                    lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer_pick == \"SGD\":\n",
    "        print(\"Using SGD Optimizer\")\n",
    "        optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                                lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    else:\n",
    "        raise Exception(f\"Invalid optimizer name: {optimizer_pick}\")\n",
    "    print(\"Loading weights\")\n",
    "    model.load_weights(weights_path, model.get_start_weight_dim())\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print('Using ', torch.cuda.device_count(), ' GPUs')\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device, non_blocking=True)\n",
    "\n",
    "    # Set scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    val_loss = 999  # using a high number for validation loss\n",
    "    val_loss_counter = 0\n",
    "    step = [0]  # wrapping in an array so it is mutable\n",
    "    epoch = start_epoch\n",
    "    while epoch < num_epochs and step[0] < num_steps and not evaluate:\n",
    "        epoch += 1\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        run_epoch(label_prefix=\"train\", data_loader=train_data_loader, epoch=epoch,\n",
    "                    step=step, model=model, num_epochs=num_epochs, num_steps=num_steps,\n",
    "                    optimizer=optimizer)\n",
    "        print('Completed epoch: ', epoch)\n",
    "        # Update best loss\n",
    "        if epoch % checkpoint_interval == 0 or epoch == num_epochs or step[0] >= num_steps:\n",
    "            # First, save the weights\n",
    "            save_weights_uri = os.path.join(output_uri, \"{epoch}.weights\".format(epoch=epoch))\n",
    "            model.save_weights(save_weights_uri)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                print(\"Calculating loss on validate data\")\n",
    "                epoch_losses, epoch_time_total, epoch_num_targets = run_epoch(\n",
    "                    label_prefix=\"validate\", data_loader=validate_data_loader, epoch=epoch,\n",
    "                    model=model, num_epochs=num_epochs, num_steps=num_steps, optimizer=None,\n",
    "                    step=step)\n",
    "                avg_epoch_loss = epoch_losses[0] / epoch_num_targets\n",
    "                print('Average Validation Loss: {0:10.6f}'.format(avg_epoch_loss))\n",
    "\n",
    "                if avg_epoch_loss > val_loss and epoch > min_epochs:\n",
    "                    val_loss_counter += 1\n",
    "                    print(f\"Validation loss did not decrease for {val_loss_counter}\"\n",
    "                            f\" consecutive check(s)\")\n",
    "                else:\n",
    "                    print(\"Validation loss decreased. Yay!!\")\n",
    "                    val_loss_counter = 0\n",
    "                    val_loss = avg_epoch_loss\n",
    "                    ##### updating best result for optuna study #####\n",
    "                    result = open(\"logs/result.txt\", \"w\" )\n",
    "                    result.write(str(avg_epoch_loss))\n",
    "                    result.close() \n",
    "                    ###########################################\n",
    "                validate.validate(dataloader=validate_data_loader, model=model, device=device, step=step[0], bbox_all=False,debug_mode=debug_mode)\n",
    "                if val_loss_counter == val_tolerance:\n",
    "                    print(\"Validation loss stopped decreasing over the last \" + str(val_tolerance) + \" checkpoints, creating onnx file\")\n",
    "                    with tempfile.NamedTemporaryFile() as tmpfile:\n",
    "                        model.save_weights(tmpfile.name)\n",
    "                        weights_name = tmpfile.name\n",
    "                        cfg_name = os.path.join(tempfile.gettempdir(), model_cfg.split('/')[-1].split('.')[0] + '.tmp')\n",
    "                        onnx_gen = subprocess.call(['python3', 'yolo2onnx.py', '--cfg_name', cfg_name, '--weights_name', weights_name])\n",
    "                        save_weights_uri = os.path.join(output_uri, onnx_name)\n",
    "                        os.rename(weights_name, save_weights_uri)\n",
    "                        try:\n",
    "                            os.remove(onnx_name)\n",
    "                        except:\n",
    "                            pass\n",
    "                        os.remove(cfg_name)\n",
    "                    break\n",
    "    if evaluate:\n",
    "        validation = validate.validate(dataloader=validate_data_loader, model=model, device=device, step=-1, bbox_all=False, tensorboard_writer=None,debug_mode=debug_mode)\n",
    "return val_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download target video file for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-25 13:54:22--  https://storage.googleapis.com/mit-driverless-open-source/test_video.mp4\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.212.128, 172.217.214.128, 172.253.119.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.212.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12062655 (12M) [video/mp4]\n",
      "Saving to: test_video.mp4\n",
      "\n",
      "test_video.mp4      100%[===================>]  11.50M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-08-25 13:54:22 (273 MB/s) - test_video.mp4 saved [12062655/12062655]\n",
      "\n",
      "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test_video.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    creation_time   : 2019-12-16T22:55:48.000000Z\n",
      "  Duration: 00:00:24.84, start: 0.000000, bitrate: 3885 kb/s\n",
      "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1024x768 [SAR 1:1 DAR 4:3], 3852 kb/s, 26 fps, 26 tbr, 13312 tbn, 26 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2019-12-16T22:55:48.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mprofile High, level 3.1\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'test.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 1\n",
      "    compatible_brands: isommp41mp42\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x768 [SAR 1:1 DAR 4:3], q=-1--1, 26 fps, 13312 tbn, 26 tbc (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2019-12-16T22:55:48.000000Z\n",
      "      handler_name    : Core Media Video\n",
      "      encoder         : Lavc57.107.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  646 fps= 83 q=-1.0 Lsize=    5168kB time=00:00:24.73 bitrate=1712.0kbits/s speed=3.17x    \n",
      "video:5163kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.111625%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mframe I:3     Avg QP:19.66  size: 20952\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mframe P:476   Avg QP:23.29  size:  8540\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mframe B:167   Avg QP:25.45  size:  6934\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mconsecutive B-frames: 60.4% 10.8% 13.9% 14.9%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mmb I  I16..4:  7.5% 88.3%  4.3%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mmb P  I16..4:  2.0% 16.6%  0.2%  P16..4: 32.5%  5.6%  1.8%  0.0%  0.0%    skip:41.4%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mmb B  I16..4:  1.3% 11.1%  0.1%  B16..8: 28.9%  4.9%  0.5%  direct: 1.8%  skip:51.4%  L0:57.7% L1:36.4% BI: 5.8%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0m8x8 transform intra:88.6% inter:87.3%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mcoded y,uvDC,uvAC intra: 63.5% 37.2% 4.3% inter: 13.9% 10.1% 0.4%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mi16 v,h,dc,p: 13% 40% 23% 24%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 14% 28% 47%  2%  1%  1%  2%  1%  3%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 18% 33% 17%  3%  7%  5%  9%  3%  4%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mi8c dc,h,v,p: 57% 22% 19%  2%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mref P L0: 65.0% 20.5%  9.9%  4.7%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mref B L0: 85.6% 11.7%  2.8%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mref B L1: 96.5%  3.5%\n",
      "\u001b[1;36m[libx264 @ 0x55b3b76ea380] \u001b[0mkb/s:1701.92\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video src=\"test.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "! wget https://storage.googleapis.com/mit-driverless-open-source/test_video.mp4\n",
    "\n",
    "! ffmpeg -i test_video.mp4 test.mp4 && rm test_video.mp4\n",
    "\n",
    "Video(\"test.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download pretrained weights for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-08-25 13:54:30--  https://storage.googleapis.com/mit-driverless-open-source/pretrained_yolo.weights\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.111.128, 172.253.119.128, 172.217.214.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.111.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 248007048 (237M) [application/octet-stream]\n",
      "Saving to: pretrained_yolo.weights\n",
      "\n",
      "pretrained_yolo.wei 100%[===================>] 236.52M   105MB/s    in 2.3s    \n",
      "\n",
      "2020-08-25 13:54:33 (105 MB/s) - pretrained_yolo.weights saved [248007048/248007048]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://storage.googleapis.com/mit-driverless-open-source/pretrained_yolo.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all packages for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import isfile, join\n",
    "import copy\n",
    "import cv2\n",
    "from tensorboardX import SummaryWriter\n",
    "from PIL import Image, ImageDraw\n",
    "import torchvision\n",
    "from utils.nms import nms\n",
    "from utils.utils import calculate_padding\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "detection_tmp_path = \"/tmp/detect/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up config file for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_path = \"test.mp4\"\n",
    "output_path = \"outputs/visualization/\"\n",
    "weights_path = \"pretrained_yolo.weights\"\n",
    "conf_thres = float(0.8)\n",
    "nms_thres = float(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_img_detect(target_path,output_path,mode,model,device,conf_thres,nms_thres):\n",
    "\n",
    "    img = Image.open(target_path).convert('RGB')\n",
    "    w, h = img.size\n",
    "    new_width, new_height = model.img_size()\n",
    "    pad_h, pad_w, ratio = calculate_padding(h, w, new_height, new_width)\n",
    "    img = torchvision.transforms.functional.pad(img, padding=(pad_w, pad_h, pad_w, pad_h), fill=(127, 127, 127), padding_mode=\"constant\")\n",
    "    img = torchvision.transforms.functional.resize(img, (new_height, new_width))\n",
    "\n",
    "    bw = model.get_bw()\n",
    "    if bw:\n",
    "        img = torchvision.transforms.functional.to_grayscale(img, num_output_channels=1)\n",
    "\n",
    "    img = torchvision.transforms.functional.to_tensor(img)\n",
    "    img = img.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        img = img.to(device, non_blocking=True)\n",
    "        # output,first_layer,second_layer,third_layer = model(img)\n",
    "        output = model(img)\n",
    "\n",
    "\n",
    "        for detections in output:\n",
    "            detections = detections[detections[:, 4] > conf_thres]\n",
    "            box_corner = torch.zeros((detections.shape[0], 4), device=detections.device)\n",
    "            xy = detections[:, 0:2]\n",
    "            wh = detections[:, 2:4] / 2\n",
    "            box_corner[:, 0:2] = xy - wh\n",
    "            box_corner[:, 2:4] = xy + wh\n",
    "            probabilities = detections[:, 4]\n",
    "            nms_indices = nms(box_corner, probabilities, nms_thres)\n",
    "            main_box_corner = box_corner[nms_indices]\n",
    "            if nms_indices.shape[0] == 0:  \n",
    "                continue\n",
    "        img_with_boxes = Image.open(target_path)\n",
    "        draw = ImageDraw.Draw(img_with_boxes)\n",
    "        w, h = img_with_boxes.size\n",
    "\n",
    "        for i in range(len(main_box_corner)):\n",
    "            x0 = main_box_corner[i, 0].to('cpu').item() / ratio - pad_w\n",
    "            y0 = main_box_corner[i, 1].to('cpu').item() / ratio - pad_h\n",
    "            x1 = main_box_corner[i, 2].to('cpu').item() / ratio - pad_w\n",
    "            y1 = main_box_corner[i, 3].to('cpu').item() / ratio - pad_h \n",
    "            draw.rectangle((x0, y0, x1, y1), outline=\"red\")\n",
    "\n",
    "        if mode == 'image':\n",
    "            img_with_boxes.save(os.path.join(output_path,target_path.split('/')[-1]))\n",
    "            return os.path.join(output_path,target_path.split('/')[-1])\n",
    "        else:\n",
    "            img_with_boxes.save(target_path)\n",
    "            return target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(target_path,\n",
    "           output_path,\n",
    "           model,\n",
    "           device,\n",
    "           conf_thres,\n",
    "           nms_thres):\n",
    "\n",
    "        target_filepath = target_path\n",
    "\n",
    "        img_formats = ['.jpg', '.jpeg', '.png', '.tif']\n",
    "        vid_formats = ['.mov', '.avi', '.mp4']\n",
    "\n",
    "        mode = None\n",
    "\n",
    "        if os.path.splitext(target_filepath)[-1].lower() in img_formats:\n",
    "            mode = 'image'\n",
    "        \n",
    "        elif os.path.splitext(target_filepath)[-1].lower() in vid_formats:\n",
    "            mode = 'video'\n",
    "        \n",
    "        print(\"Detection Mode is: \" + mode)\n",
    "\n",
    "        raw_file_name = target_filepath.split('/')[-1].split('.')[0].split('_')[-4:]\n",
    "        raw_file_name = '_'.join(raw_file_name)\n",
    "        \n",
    "        if mode == 'image':\n",
    "            detection_path = single_img_detect(target_path=target_filepath,output_path=output_path,mode=mode,model=model,device=device,conf_thres=conf_thres,nms_thres=nms_thres)\n",
    "\n",
    "            print(f'Please check output image at {detection_path}')\n",
    "\n",
    "        elif mode == 'video':\n",
    "            if os.path.exists(detection_tmp_path):\n",
    "                shutil.rmtree(detection_tmp_path)  # delete output folder\n",
    "            os.makedirs(detection_tmp_path)  # make new output folder\n",
    "\n",
    "            vidcap = cv2.VideoCapture(target_filepath)\n",
    "            success,image = vidcap.read()\n",
    "            count = 0\n",
    "\n",
    "            \n",
    "\n",
    "            while success:\n",
    "                cv2.imwrite(detection_tmp_path + \"/frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "                success,image = vidcap.read()\n",
    "                count += 1\n",
    "\n",
    "            # Find OpenCV version\n",
    "            (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "            if int(major_ver)  < 3 :\n",
    "                fps = vidcap.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "                print (\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "            else :\n",
    "                fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "                print (\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "            vidcap.release(); \n",
    "\n",
    "            frame_array = []\n",
    "            files = [f for f in os.listdir(detection_tmp_path) if isfile(join(detection_tmp_path, f))]\n",
    "        \n",
    "            #for sorting the file names properly\n",
    "            files.sort(key = lambda x: int(x[5:-4]))\n",
    "            for i in tqdm(files,desc='Doing Single Image Detection'):\n",
    "                filename=detection_tmp_path + i\n",
    "                \n",
    "                detection_path = single_img_detect(target_path=filename,output_path=output_path,mode=mode,model=model,device=device,conf_thres=conf_thres,nms_thres=nms_thres)\n",
    "                #reading each files\n",
    "                img = cv2.imread(detection_path)\n",
    "                height, width, layers = img.shape\n",
    "                size = (width,height)\n",
    "                frame_array.append(img)\n",
    "\n",
    "            local_output_uri = output_path + raw_file_name + \".mp4\"\n",
    "            \n",
    "            video_output = cv2.VideoWriter(local_output_uri,cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "            for frame in tqdm(frame_array,desc='Creating Video'):\n",
    "                # writing to a image array\n",
    "                video_output.write(frame)\n",
    "            video_output.release()\n",
    "            shutil.rmtree(detection_tmp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection Mode is: video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Doing Single Image Detection:   0%|          | 0/646 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.CAP_PROP_FPS) : 26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Doing Single Image Detection: 100%|| 646/646 [01:15<00:00,  8.55it/s]\n",
      "Creating Video: 100%|| 646/646 [00:03<00:00, 184.07it/s]\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda:0' if cuda else 'cpu')\n",
    "random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(0)\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.cuda.empty_cache()\n",
    "model = Darknet(config_path=model_cfg,xy_loss=xy_loss,wh_loss=wh_loss,no_object_loss=no_object_loss,object_loss=object_loss,vanilla_anchor=vanilla_anchor)\n",
    "\n",
    "# Load weights\n",
    "model.load_weights(weights_path, model.get_start_weight_dim())\n",
    "model.to(device, non_blocking=True)\n",
    "\n",
    "detect(target_path,\n",
    "        output_path,\n",
    "        model,\n",
    "        device=device,\n",
    "        conf_thres=conf_thres,\n",
    "        nms_thres=nms_thres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.8-0ubuntu0.2 Copyright (c) 2000-2020 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.5.0-3ubuntu1~18.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.2 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'test.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf58.49.100\n",
      "  Duration: 00:00:24.85, start: 0.000000, bitrate: 3487 kb/s\n",
      "    Stream #0:0(und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 1024x768 [SAR 1:1 DAR 4:3], 3486 kb/s, 26 fps, 26 tbr, 13312 tbn, 26 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0musing SAR=1/1\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0musing cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mprofile High, level 3.1\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0m264 - core 152 r2854 e9a5903 - H.264/MPEG-4 AVC codec - Copyleft 2003-2017 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'output.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(und): Video: h264 (libx264) (avc1 / 0x31637661), yuv420p, 1024x768 [SAR 1:1 DAR 4:3], q=-1--1, 26 fps, 13312 tbn, 26 tbc (default)\n",
      "    Metadata:\n",
      "      handler_name    : VideoHandler\n",
      "      encoder         : Lavc57.107.100 libx264\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: -1\n",
      "frame=  646 fps= 83 q=-1.0 Lsize=    5441kB time=00:00:24.73 bitrate=1802.3kbits/s speed=3.19x    \n",
      "video:5436kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.094948%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mframe I:3     Avg QP:17.90  size: 20264\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mframe P:534   Avg QP:22.65  size:  8861\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mframe B:109   Avg QP:24.62  size:  7092\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mconsecutive B-frames: 72.6% 11.8%  8.8%  6.8%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mmb I  I16..4: 33.9% 63.4%  2.7%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mmb P  I16..4:  2.8% 16.4%  0.2%  P16..4: 33.0%  5.0%  1.6%  0.0%  0.0%    skip:40.9%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mmb B  I16..4:  1.8% 12.5%  0.2%  B16..8: 29.8%  4.2%  0.4%  direct: 1.4%  skip:49.6%  L0:66.1% L1:29.0% BI: 4.9%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0m8x8 transform intra:84.2% inter:88.8%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mcoded y,uvDC,uvAC intra: 54.3% 46.2% 6.7% inter: 12.5% 14.6% 1.8%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mi16 v,h,dc,p: 22% 38% 24% 16%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mi8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 31% 43%  2%  1%  1%  2%  1%  2%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mi4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 32% 34% 14%  2%  4%  3%  5%  2%  3%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mi8c dc,h,v,p: 52% 24% 22%  2%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mWeighted P-Frames: Y:0.0% UV:0.0%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mref P L0: 69.6% 17.0%  9.4%  4.0%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mref B L0: 86.1% 12.0%  1.9%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mref B L1: 97.8%  2.2%\n",
      "\u001b[1;36m[libx264 @ 0x5583368aeae0] \u001b[0mkb/s:1791.99\n"
     ]
    }
   ],
   "source": [
    "! cd outputs/visualization/ && ffmpeg -i test.mp4 output.mp4 && rm test.mp4 && cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"outputs/visualization/output.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"outputs/visualization/output.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** Again, you can further improve the accuracy of the cone detection network by switching YOLOv3 backbone to the most recent published YOLOv4\n",
    "\n",
    "![](https://user-images.githubusercontent.com/22118253/70950893-e2de6980-202f-11ea-9a16-399579926ee5.gif)\n",
    "\n",
    "Congratulations! You've finished all the content of this tutorial!\n",
    "Hope you enjoy playing with the our object detection model. If you are interested,  please refer to our paper and GitHub Repo for further details.\n",
    "\n",
    "## Reference\n",
    "[1] Kieran Strobel, Sibo Zhu, Raphael Chang and Skanda Koppula.\n",
    "**Accurate, Low-Latency Visual Perception for Autonomous Racing:Challenges, Mechanisms, and Practical Solutions**. In *IROS* 2020.\n",
    "[[paper]](https://arxiv.org/abs/2007.13971), [[code]](https://github.com/cv-core/MIT-Driverless-CV-TrainingInfra)."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bitfb145c69a41e49ec9393ba0ede4656b6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
